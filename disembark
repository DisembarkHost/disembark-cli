#!/usr/bin/env php
<?php
namespace Disembark;

class Run {

    const VERSION = '2.4.0';

    public static function main($argv, $argc) {
        if ($argc < 2) {
            self::showHelp();
            exit(0);
        }

        $command = $argv[1];
        switch ($command) {
            case 'connect':
                if ($argc != 4) {
                    echo "Error: Invalid arguments for connect\n";
                    exit(1);
                }
                $siteUrl = $argv[2];
                $token = $argv[3];
                self::connect($siteUrl, $token);
                break;

            case 'list':
                if ($argc != 2) {
                    echo "Error: Invalid arguments for list\n";
                    exit(1);
                }
                self::sites();
                break;
            case 'backup':
                if ($argc < 3) {
                    echo "Error: Invalid arguments for backup\nRequires: <site-url> [options]\n";
                    exit(1);
                }
                $siteUrl = $argv[2];
                $exclude_paths = [];
                $exclude_tables_str = '';
                $preview = false;
                $token = null;
                $session_id = null;
                $db_max_size_str = null;
                $db_max_rows_str = null;
                $skip_db = false;
                $skip_files = false;
                $i = 3;
                while ($i < $argc) {
                    if ($argv[$i] === '--preview') {
                        $preview = true;
                        $i++;
                        continue;
                    }
                    if ($argv[$i] === '--skip-db') {
                        $skip_db = true;
                        $i++;
                        continue;
                    }
                    if ($argv[$i] === '--skip-files') {
                        $skip_files = true;
                        $i++;
                        continue;
                    }
                    if (strpos($argv[$i], '--token=') === 0) {
                        $token = substr($argv[$i], strlen('--token='));
                        $i++;
                        continue;
                    }
                    if (strpos($argv[$i], '--session-id=') === 0) {
                        $session_id = substr($argv[$i], strlen('--session-id='));
                        $i++;
                        continue;
                    }
                    if ($argv[$i] === '-x') {
                        if (isset($argv[$i + 1])) {
                            $exclude_paths[] = rtrim($argv[$i + 1], '/');
                            $i += 2;
                        } else {
                            echo "Error: Missing value for -x option.\n";
                            exit(1);
                        }
                    } elseif (strpos($argv[$i], '--exclude-tables=') === 0) {
                        $exclude_tables_str = substr($argv[$i], strlen('--exclude-tables='));
                        $i++;
                    } elseif (strpos($argv[$i], '--db-max-size=') === 0) {
                        $db_max_size_str = substr($argv[$i], strlen('--db-max-size='));
                        $i++;
                    } elseif (strpos($argv[$i], '--db-max-rows=') === 0) {
                        $db_max_rows_str = substr($argv[$i], strlen('--db-max-rows='));
                        $i++;
                    } else {
                        echo "Error: Unknown argument '{$argv[$i]}'\n";
                        self::showHelp();
                        exit(1);
                    }
                }
                $exclude_tables = !empty($exclude_tables_str) ? explode(',', $exclude_tables_str) : [];
                self::backup($siteUrl, $exclude_paths, $exclude_tables, $preview, $session_id, $db_max_size_str, $db_max_rows_str, $skip_db, $skip_files, $token);
                break;
            case 'version':
                if ($argc != 2) {
                    echo "Error: Invalid arguments for version\n";
                    exit(1);
                }
                self::version();
                break;
            case 'upgrade':
                if ($argc != 2) {
                    echo "Error: Invalid arguments for upgrade\n";
                    exit(1);
                }
                self::upgrade();
                break;
            case 'sync':
                if ($argc < 3) {
                    echo "Error: Invalid arguments for sync\nRequires: <site-url> [<folder>] [--debug]\n";
                    exit(1);
                }
                $siteUrl = $argv[2];
                // Initialize variables
                $folder = null;
                $debug = false;
                $session_id = null;
                $db_max_size_str = null;
                $db_max_rows_str = null;
                $file_chunk_size_str = null;
                $file_chunk_max_size_str = null;
                $skip_db = false;
                $skip_files = false;
                $exclude_paths = []; // Initialize exclusion array
                $skip_checksums = false;

                $i = 3;
                while ($i < $argc) {
                    if ($argv[$i] === '--debug') {
                        $debug = true;
                        $i++;
                        continue;
                    }
                    if ($argv[$i] === '--skip-db') {
                        $skip_db = true;
                        $i++;
                        continue;
                    }
                    if ($argv[$i] === '--skip-files') {
                        $skip_files = true;
                        $i++;
                        continue;
                    }
                    if ($argv[$i] === '--skip-checksums') {
                        $skip_checksums = true;
                        $i++;
                        continue;
                    }
                    if (strpos($argv[$i], '--session-id=') === 0) {
                        $session_id = substr($argv[$i], strlen('--session-id='));
                        $i++;
                        continue;
                    }
                    if ($argv[$i] === '-x') {
                        if (isset($argv[$i + 1])) {
                            $exclude_paths[] = rtrim($argv[$i + 1], '/');
                            $i += 2;
                            continue;
                        } else {
                            echo "Error: Missing value for -x option.\n";
                            exit(1);
                        }
                    }
                    if (strpos($argv[$i], '--db-max-size=') === 0) {
                        $db_max_size_str = substr($argv[$i], strlen('--db-max-size='));
                        $i++;
                        continue;
                    }
                    if (strpos($argv[$i], '--db-max-rows=') === 0) {
                        $db_max_rows_str = substr($argv[$i], strlen('--db-max-rows='));
                        $i++;
                        continue;
                    }
                    if (strpos($argv[$i], '--file-chunk-size=') === 0) {
                        $file_chunk_size_str = substr($argv[$i], strlen('--file-chunk-size='));
                        $i++;
                        continue;
                    }
                    if (strpos($argv[$i], '--file-chunk-max-size=') === 0) {
                        $file_chunk_max_size_str = substr($argv[$i], strlen('--file-chunk-max-size='));
                        $i++;
                        continue;
                    }
                    
                    // Handle folder argument (checking if it's not a flag)
                    if ($folder === null && strpos($argv[$i], '--') !== 0) {
                        $folder = $argv[$i];
                        $i++;
                        continue;
                    }

                    echo "Error: Unknown argument '{$argv[$i]}'\n";
                    self::showHelp();
                    exit(1);
                }

                if ($folder === null) {
                    $folder = preg_replace('/^https?:\/\/(www\.)?/', '', rtrim($siteUrl, '/'));
                }

                // Resolve $folder to an absolute path to avoid phar ambiguity.
                // Check if $folder is already absolute (e.g., /var/www or C:\www)
                if ( substr($folder, 0, 1) !== DIRECTORY_SEPARATOR && !(strlen($folder) > 1 && substr($folder, 1, 1) === ':') ) {
                    $folder = getcwd() . DIRECTORY_SEPARATOR . $folder;
                }

                self::sync($siteUrl, $folder, $debug, $session_id, $db_max_size_str, $db_max_rows_str, $file_chunk_size_str, $skip_db, $file_chunk_max_size_str, $skip_files, $exclude_paths, $skip_checksums);
                break;
            case 'ncdu':
                if ($argc < 3) {
                    echo "Error: Invalid arguments for ncdu\nRequires: <site-url> [--session-id=<id>] [--debug]\n";
                    exit(1);
                }
                $siteUrl = $argv[2];
                $session_id = null;
                $debug = false;

                // Parse arguments
                $args = array_slice($argv, 3);
                foreach ($args as $arg) {
                    if (strpos($arg, '--session-id=') === 0) {
                        $session_id = substr($arg, strlen('--session-id='));
                    } elseif ($arg === '--debug') {
                        $debug = true;
                    } else {
                        echo "Error: Unknown argument '{$arg}'\n";
                        self::showHelp();
                        exit(1);
                    }
                }
                self::ncdu($siteUrl, $session_id, $debug);
                break;
            default:
                echo "Error: Unknown command '$command'.\n\n";
                self::showHelp();
                exit(1);
        }
    }

    private static function connect($siteUrl, $token) {
        // Trim trailing slashes from the site URL
        $siteUrl = rtrim($siteUrl, '/');
        // Verify the site URL starts with http:// or https://
        if (!preg_match('/^https?:\/\//', $siteUrl)) {
            $siteUrl = "https://$siteUrl";
            echo "The site URL must start with http:// or https://. Attempting to use $siteUrl\n";
        }

        $homeDir = getenv('HOME');
        if (!$homeDir) {
            echo "Error: Unable to determine the home directory.\n";
            exit(1);
        }

        if (empty($siteUrl) || empty($token)) {
            echo "Error: Required arguments <site-url> and <token>.\n";
            exit(1);
        }
        try {
            // Test connection by fetching database info
            $response = \WpOrg\Requests\Requests::get("$siteUrl/wp-json/disembark/v1/database?token=$token", [], ['verify' => false, 'timeout' => 60]);
        } catch (\WpOrg\Requests\Exception $e) {
            // Handle the exception
            echo "Error: Request failed with error: {$e->getMessage()}\n";
            exit(1);
        }

        if ($response->status_code != 200) {
            echo "Error: Failed to connect to $siteUrl. Status code: {$response->status_code}. Please check your URL, token, and ensure the Disembark plugin is active.\n";
            exit(1);
        }

        $tables = json_decode($response->body);
        if (empty($tables)) {
            echo "Error: Connected to $siteUrl, but failed to retrieve database information. Please check plugin functionality.\n";
            exit(1);
        }

        $filePath = $homeDir . '/.disembark';
        $data = [];
        // Check if the file already exists and read its contents
        if (file_exists($filePath)) {
            $jsonContents = file_get_contents($filePath);
            $data = json_decode($jsonContents);
            // Ensure $data is always an array for consistent processing
            if (!is_array($data)) {
                // Try decoding as an object first for legacy compatibility
                if (is_object($data)) {
                    // Convert object to array of objects
                    $data = [$data];
                } else {
                    $data = []; // Initialize as empty array if decoding failed or was invalid
                }
            }
        }

        // Check if the siteUrl already exists and update it, otherwise add new
        $found = false;
        foreach ($data as $key => $entry) {
            // Ensure entry is an object before accessing properties
            if (is_object($entry) && !empty($entry->siteUrl) && $entry->siteUrl === $siteUrl) {
                $data[$key]->token = $token; // Update token directly on the object within the array
                $found = true;
                break;
            }
        }

        if (!$found) {
            // Add new entry as an object
            $data[] = (object) [
                'siteUrl' => $siteUrl,
                'token' => $token
            ];
        }

        $jsonData = json_encode($data, JSON_PRETTY_PRINT);
        if (file_put_contents($filePath, $jsonData) === false) {
            echo "Error: Unable to write to $filePath.\n";
            exit(1);
        }

        echo "Successfully connected to $siteUrl and saved credentials to $filePath\n";
    }

    private static function make_request($siteUrl, $token, $backup_token, $endpoint, $payload = [], $method = 'POST') {
        $headers = ['Content-Type' => 'application/json; charset=utf-8'];
        $data = array_merge(['token' => $token, 'backup_token' => $backup_token], $payload);
        $url = "$siteUrl/wp-json/disembark/v1" . $endpoint;
        $options = ['verify' => false, 'timeout' => 600]; // Standard timeout for most steps

        try {
            switch (strtoupper($method)) {
                case 'POST':
                    // Increase timeout specifically for zip operations which can take longer
                    if ($endpoint === '/zip-files' || $endpoint === '/zip-database') {
                        $options['timeout'] = 1800; // 30 minutes
                    } elseif (strpos($endpoint, '/export/database/') === 0 && isset($payload['parts'])) {
                        $options['timeout'] = 1200; // 20 minutes for large table parts
                    }
                    $response = \WpOrg\Requests\Requests::post($url, $headers, json_encode($data), $options);
                    break;
                case 'GET':
                default:
                    // Increase timeout for cleanup as well
                    if ($endpoint === '/cleanup') {
                        $options['timeout'] = 120;
                    }
                    // For GET, build query params correctly
                    $query_params = http_build_query($data);
                    $response = \WpOrg\Requests\Requests::get($url . '?' . $query_params, [], $options); // Pass empty headers array for GET
                    break;
            }

            if ($response->status_code !== 200) {
                $errorMessage = "Error: Request to {$endpoint} failed. HTTP status: {$response->status_code}.";
                $errorBody = json_decode($response->body);
                if (json_last_error() === JSON_ERROR_NONE && isset($errorBody->message)) {
                    $errorMessage .= " Message: " . $errorBody->message;
                } else {
                    $errorMessage .= " Response: " . substr($response->body, 0, 500);
                }
                echo $errorMessage . "\n";
                // Throw an exception instead of exiting directly to allow potential cleanup
                throw new \Exception("API request failed for {$endpoint}");
            }

            $decoded = json_decode($response->body);
            // Check if this endpoint is allowed to return a raw string (like a path or URL)
            $allowed_raw_endpoints = ['/cleanup', '/zip-database', '/zip-files'];
            $is_raw_endpoint = false;
            foreach ($allowed_raw_endpoints as $raw_ep) {
                if ($endpoint === $raw_ep) $is_raw_endpoint = true;
            }
            if (strpos($endpoint, '/export/database/') === 0) {
                $is_raw_endpoint = true;
            }

            if (json_last_error() !== JSON_ERROR_NONE) {
                // Not JSON.
                // Is it an endpoint that *should* return a raw string?
                if (!empty(trim($response->body)) && $is_raw_endpoint) {
                    return trim($response->body); // Return the raw body (e.g., URL)
                }
                // Not JSON and not an allowed raw endpoint, or it's empty
                if (!empty(trim($response->body))) {
                    echo "Error: Could not decode JSON response from {$endpoint}. Response: " . substr($response->body, 0, 500) . "\n";
                    throw new \Exception("Invalid JSON response for {$endpoint}");
                }
                // Allow empty responses for cleanup
                if ($endpoint === '/cleanup') {
                    return "Cleanup requested";
                }
            }

            // If it *is* valid JSON, but the API might have returned a JSON-encoded string (e.g. "path\/to\/file.sql")
            // json_decode will have correctly turned this into a PHP string.
            // If it was a JSON object/array, it will be a PHP object/array.
            return $decoded;
        } catch (\WpOrg\Requests\Exception $e) {
            echo "Error: Request failed for {$endpoint}: {$e->getMessage()}\n";
            // Re-throw or handle as needed
            throw $e; // Re-throw to allow potential cleanup in calling function
        }
    }

    /**
     * Runs the remote manifest generation process.
     * Can optionally request file checksums for sync operations.
     * @return array List of manifest chunk file objects.
     */
    private static function runManifestGeneration($siteUrl, $token, $backup_token, $exclude_paths, $include_checksums = false) {

        $files_manifests = [];
        try {
            echo "Running analysis (this may take a while)...\n";
            $exclude_files_string = implode("\n", $exclude_paths);

            $payload = [
                'exclude_files' => $exclude_files_string
            ];
            if ($include_checksums) {
                $payload['include_checksums'] = true;
            }

            // Step 1: Initiate
            self::make_request($siteUrl, $token, $backup_token, '/regenerate-manifest', ['step' => 'initiate'] + $payload, 'POST');
            echo "Initiated file scan.\n";

            // Step 2: Scan Loop
            $scan_complete = false;
            $last_scan_output = "";
            while (!$scan_complete) {
                $scan_response = self::make_request($siteUrl, $token, $backup_token, '/regenerate-manifest', ['step' => 'scan'] + $payload, 'POST');
                if (!is_object($scan_response) || !isset($scan_response->status)) {
                    throw new \Exception("Invalid response received during scan step.");
                }

                if ($scan_response->status === 'scan_complete') {
                    $scan_complete = true;
                    echo str_pad("", strlen($last_scan_output), " ") . "\r";
                    printf("Scanning complete. Analyzed %d directories.\n", $scan_response->total_dirs ?? 0);
                } else if (isset($scan_response->scanned_dirs) && isset($scan_response->total_dirs)) {
                    $last_scan_output = sprintf("Scanning... (%d / %d directories)", $scan_response->scanned_dirs, $scan_response->total_dirs);
                    echo $last_scan_output . "\r";
                } else {
                    echo "\nWarning: Scan step response might be incomplete.\n";
                }
                usleep(250000);
            }

            // Step 3: Chunkify
            echo "Chunkifying file list...\n";
            $chunk_response = self::make_request($siteUrl, $token, $backup_token, '/regenerate-manifest', ['step' => 'chunkify'] + $payload, 'POST');
            $total_chunks = $chunk_response->total_chunks ?? 0;
            if ($total_chunks === 0) {
                echo "No files found to analyze or an error occurred during chunkification.\n";
            } else {
                echo "File list divided into {$total_chunks} chunks.\n";
            }


            // Step 4: Process Chunks
            $last_chunk_output = "";
            for ($i = 1; $i <= $total_chunks; $i++) {
                $last_chunk_output = sprintf("Processing chunk %d of %d...", $i, $total_chunks);
                echo $last_chunk_output . "\r";
                self::make_request($siteUrl, $token, $backup_token, '/regenerate-manifest', ['step' => 'process_chunk', 'chunk' => $i] + $payload, 'POST');
                usleep(50000);
            }
            if ($total_chunks > 0) {
                echo str_pad("", strlen($last_chunk_output), " ") . "\r";
                echo "Chunk processing complete.\n";
            }


            // Step 5: Finalize
            $files_manifests = self::make_request($siteUrl, $token, $backup_token, '/regenerate-manifest', ['step' => 'finalize'] + $payload, 'POST');
            if (!is_array($files_manifests)) {
                echo "Warning: Final manifest data is not in the expected format. File stats may be inaccurate.\n";
                $files_manifests = [];
            }
            echo "Analysis complete.\n";
        } catch (\Exception $e) {
            echo "Error during file analysis: {$e->getMessage()}\n";
            self::cleanupTemporaryFiles($siteUrl, $token, $backup_token); // Attempt cleanup
            exit(1);
        }

        // Return the generated manifest
        return $files_manifests;
    }

    private static function displayBackupSummary($siteUrl, $token, $files_manifests, $exclude_tables) {
        // 2. Fetch database info
        $all_tables = [];
        try {
            $response_db = \WpOrg\Requests\Requests::get("$siteUrl/wp-json/disembark/v1/database?token=$token", [], ['verify' => false, 'timeout' => 600]);
            if ($response_db->status_code !== 200) {
                echo "Error: Failed to fetch database info. HTTP response code: {$response_db->status_code}\n";
                exit(1);
            }
            $all_tables = json_decode($response_db->body);
            if (json_last_error() !== JSON_ERROR_NONE || !is_array($all_tables)) {
                echo "Error: Invalid database info received.\n";
                $all_tables = [];
            }
        } catch (\WpOrg\Requests\Exception $e) {
            echo "Error: Failed to fetch database info: {$e->getMessage()}\n";
            exit(1);
        }

        // 3. Calculate file stats TO BE BACKED UP
        $remainingFiles = empty($files_manifests) ? 0 : array_sum(array_column($files_manifests, 'count'));
        $remainingSize = empty($files_manifests) ? 0 : array_sum(array_column($files_manifests, 'size'));
        // 4. Calculate database stats
        $totalTables = count($all_tables);
        $totalDbSize = empty($all_tables) ? 0 : array_sum(array_column($all_tables, 'size'));
        $excludedTables = 0;
        $excludedDbSize = 0;

        $included_table_list = [];
        foreach ($all_tables as $table) {
            $table_size = isset($table->size) && is_numeric($table->size) ? (float)$table->size : 0;
            $is_excluded = false;
            foreach ($exclude_tables as $pattern) {
                if (fnmatch($pattern, $table->table)) {
                    $is_excluded = true;
                    break;
                }
            }
            if ($is_excluded) {
                $excludedTables++;
                $excludedDbSize += $table_size;
            } else {
                $table->size = $table_size;
                $included_table_list[] = $table;
            }
        }
        $remainingTables = $totalTables - $excludedTables;
        $remainingDbSize = empty($included_table_list) ? 0 : array_sum(array_column($included_table_list, 'size'));


        // 5. Display results
        echo "\nBackup Preview: $siteUrl\n";
        echo "* Exclusions are applied server-side during analysis.\n";
        echo "* The summary below shows only files and tables scheduled for backup.\n\n";
        echo "File Backup Summary\n";
        printf("%-24s %12s %12s\n", "", "Count", "Size");
        printf("%-24s %12s %12s\n", str_repeat('-', 24), str_repeat('-', 12), str_repeat('-', 12));
        printf("%-24s %12s %12s\n", "Files to be Backed Up:", number_format($remainingFiles), self::humanFilesize($remainingSize));

        echo "\nDatabase Backup Summary\n";
        printf("%-24s %12s %12s\n", "", "Count", "Size");
        printf("%-24s %12s %12s\n", str_repeat('-', 24), str_repeat('-', 12), str_repeat('-', 12));
        printf("%-24s %12s %12s\n", "Total Tables:", number_format($totalTables), self::humanFilesize($totalDbSize));
        printf("%-24s %12s %12s\n", "Excluded Tables:", number_format($excludedTables), self::humanFilesize($excludedDbSize));
        printf("%-24s %12s %12s\n", "Tables to be Backed Up:", number_format($remainingTables), self::humanFilesize($remainingDbSize));
        echo "\n* This is an estimate. Actual backup size may vary.\n";
    }

    private static function runPreview($siteUrl, $token, $backup_token, $exclude_paths, $exclude_tables) {

        // 1. Run the manifest generation
        $files_manifests = self::runManifestGeneration($siteUrl, $token, $backup_token, $exclude_paths, false);
        // 2. Display the summary
        self::displayBackupSummary($siteUrl, $token, $files_manifests, $exclude_tables);
        // 3. Return the generated manifest
        return $files_manifests;
    }

    // Helper function specifically for cleanup after preview or backup failure
    private static function cleanupTemporaryFiles($siteUrl, $token, $backup_token) {
        echo "Cleaning up temporary files on server...\n";
        try {
            $payload = ['backup_token' => $backup_token];
            self::make_request($siteUrl, $token, $backup_token, '/cleanup', $payload, 'GET');
            echo "Cleanup request sent.\n";
        } catch (\Exception $e) {
            echo "Warning: Cleanup request failed: {$e->getMessage()}\n";
            // Don't exit here, cleanup failure is not critical for the overall process
        }
    }

    /**
     * Processes the database backup using hybrid batching.
     *
     * @param string $siteUrl
     * @param string $token
     * @param string $backup_token
     * @param array $tables_to_backup List of table objects to be backed up.
     * @param string $db_export_file The final, local SQL file path to append to.
     * @param string $local_db_parts_path A temporary directory to store downloaded SQL chunks.
     * @throws \Exception
     */
    private static function processDatabaseBackup($siteUrl, $token, $backup_token, $tables_to_backup, $db_export_file, $local_db_parts_path, $max_size, $max_rows) {
        
        echo "Backing up database tables...\n";
        // --- Hybrid Batching Logic ---
        $large_tables = [];
        $small_tables = [];

        foreach ($tables_to_backup as $table) {
            $table_size = isset($table->size) && is_numeric($table->size) ? (float)$table->size : 0;
            $row_count = isset($table->row_count) && is_numeric($table->row_count) ? (int)$table->row_count : 0;
            if (($table_size > $max_size || $row_count > $max_rows) && $row_count > 0) {
                $parts_by_size = ceil($table_size / $max_size);
                $parts_by_rows = ceil($row_count / $max_rows);
                $parts = max($parts_by_size, $parts_by_rows);
                
                $table->parts = $parts;
                $table->current = 0;
                $table->rows_per_part = ceil($row_count / $parts);
                $large_tables[] = $table;
            } else {
                $table->parts = 0;
                $small_tables[] = $table;
            }
        }

        $small_table_batches = [];
        $current_batch = [];
        $current_batch_size = 0;
        foreach ($small_tables as $table) {
            $table_size = isset($table->size) && is_numeric($table->size) ? (float)$table->size : 0;
            if ($current_batch_size + $table_size > $max_size && !empty($current_batch)) {
                $small_table_batches[] = $current_batch;
                $current_batch = [];
                $current_batch_size = 0;
            }
            $current_batch[] = $table;
            $current_batch_size += $table_size;
        }
        if (!empty($current_batch)) {
            $small_table_batches[] = $current_batch;
        }
        // --- End Hybrid Batching ---

        // Calculate total steps
        $total_db_steps = count($small_table_batches);
        foreach ($large_tables as $table) {
            $total_db_steps += ($table->parts > 0) ? $table->parts : 1;
        }
        $current_db_step = 0;

        // --- Loop 1: Process small table batches ---
        foreach ($small_table_batches as $batch) {
            $current_db_step++;
            $table_names = array_column($batch, 'table');
            $batch_size = array_sum(array_column($batch, 'size'));
            $progress_message = sprintf(" - Exporting batch %d/%d (%d tables, %s)", $current_db_step, $total_db_steps, count($batch), self::humanFilesize($batch_size));
            echo $progress_message . "...\r";

            $file_url = self::make_request($siteUrl, $token, $backup_token, "/export-database-batch", ['tables' => $table_names], 'POST');
            if (strpos($file_url, 'http') !== 0) {
                throw new \Exception("Export failed for batch, did not receive a valid URL. Got: $file_url");
            }
            $file_name = basename($file_url);
            $local_file_path = $local_db_parts_path . '/' . $file_name;

            $parsed_url = parse_url($file_url);
            $relative_path = ltrim($parsed_url['path'], '/');
            self::download_db_file($siteUrl, $token, $relative_path, $local_file_path);

            file_put_contents($db_export_file, file_get_contents($local_file_path), FILE_APPEND);
            unlink($local_file_path); // Delete local SQL part

            self::make_request($siteUrl, $token, $backup_token, '/cleanup-file', ['file_name' => $file_name], 'POST');
            echo $progress_message . " - Done.\n";
            usleep(50000);
        }

        // --- Loop 2: Process large tables ---
        foreach ($large_tables as $table) {
            if (!isset($table->table)) {
                echo "\nWarning: Skipping invalid table data entry in backup.\n";
                continue;
            }

            for ($part = 1; $part <= $table->parts; $part++) {
                $current_db_step++;
                $total_table_size = (float)$table->size;
                $row_count = isset($table->row_count) && is_numeric($table->row_count) ? (int)$table->row_count : 0;
                
                // Determine what the size of this part *should* be for logging
                $current_part_size = 0;
                
                // Recalculate parts to see which logic won
                $parts_by_size = ($max_size > 0) ? ceil($total_table_size / $max_size) : 1;
                $parts_by_rows = ($max_rows > 0) ? ceil($row_count / $max_rows) : 1;
                
                if ($parts_by_rows > $parts_by_size) {
                    // Row-based split. Estimate size.
                    $current_part_size = $total_table_size / $table->parts;
                } else {
                    // Size-based split.
                    $current_part_size = $max_size;
                }

                if ($part == $table->parts) {
                    // Last part. Calculate remaining size.
                    // This is the size of all previous parts.
                    $previous_parts_size = $current_part_size * ($table->parts - 1);
                    $current_part_size = $total_table_size - $previous_parts_size;
                }
                
                $description = sprintf("%s %d/%d", $table->table, $part, $table->parts);
                // Use max(0, ...) to prevent any weird negative display
                $size_string = self::humanFilesize(max(0, $current_part_size));
                $progress_message = sprintf(" - Exporting batch %d/%d (%s, %s)", $current_db_step, $total_db_steps, $description, $size_string);
                echo $progress_message . "...\r";
                
                $part_data = ['parts' => $part, 'rows_per_part' => $table->rows_per_part];
                $file_url = self::make_request($siteUrl, $token, $backup_token, "/export/database/{$table->table}", $part_data, 'POST');
                if (strpos($file_url, 'http') !== 0) {
                    throw new \Exception("Export failed, did not receive a valid URL. Got: $file_url");
                }
                $file_name = basename($file_url);
                $local_file_path = $local_db_parts_path . '/' . $file_name;

                $parsed_url = parse_url($file_url);
                $relative_path = ltrim($parsed_url['path'], '/');
                self::download_db_file($siteUrl, $token, $relative_path, $local_file_path);
                file_put_contents($db_export_file, file_get_contents($local_file_path), FILE_APPEND);
                unlink($local_file_path); // Delete local SQL part

                self::make_request($siteUrl, $token, $backup_token, '/cleanup-file', ['file_name' => $file_name], 'POST');
                echo $progress_message . " - Done.\n";
                usleep(50000);
            }
        }
        echo "Database export and download complete.\n";
    }

   /**
     * Performs a local or remote sync.
     */
    private static function sync($siteUrl, $folder, $debug = false, $session_id = null, $db_max_size_str = null, $db_max_rows_str = null, $file_chunk_size_str = null, $skip_db = false, $file_chunk_max_size_str = null, $skip_files = false, $exclude_paths = [], $skip_checksums = false) {
        // --- 1. Authentication ---
        $siteUrl = rtrim($siteUrl, '/');
        if (!preg_match('/^https?:\/\//', $siteUrl)) {
            $siteUrl = "https://$siteUrl";
        }
        $homeDir = getenv('HOME');
        if (!$homeDir) {
            echo "Error: Unable to determine the home directory.\n";
            exit(1);
        }
        $filePath = $homeDir . '/.disembark';
        $data = [];
        if (file_exists($filePath)) {
            $data = json_decode(file_get_contents($filePath));
            if (!is_array($data)) {
                if (is_object($data)) $data = [$data];
                else {
                    echo "Error: Invalid data in $filePath.\n";
                    exit(1);
                }
            }
        } else {
            echo "Error: No configuration file found at $filePath.\n";
            exit(1);
        }
        $token = null;
        foreach ($data as $entry) {
            if (is_object($entry) && isset($entry->siteUrl) && $entry->siteUrl === $siteUrl) {
                $token = $entry->token;
                break;
            }
        }
        if (empty($token)) {
            echo "Error: No token found for $siteUrl.\n";
            exit(1);
        }

        // --- 2. Setup ---
        $backup_token = "";
        if ($session_id) {
            $backup_token = $session_id;
            echo "Reusing backup session: $backup_token\n";
        } else {
            $backup_token = substr(bin2hex(random_bytes(20)), 0, -28);
        }
        $is_initial_sync = !is_dir($folder);
        if ($is_initial_sync) {
            echo "Performing initial sync to new folder: $folder\n";
            if (!mkdir($folder, 0755, true)) {
                echo "Error: Could not create folder at $folder.\n";
                exit(1);
            }
        } else {
            echo "Performing subsequent sync to existing folder: $folder\n";
        }

        // Convert DB threshold arguments, using defaults if not provided
        $db_max_size = $db_max_size_str ? self::convert_to_bytes($db_max_size_str) : 209715200; // 200MB default
        $db_max_rows = $db_max_rows_str ? (int)$db_max_rows_str : 1000000; // 1M rows default
        $file_chunk_size = $file_chunk_size_str ? (int)$file_chunk_size_str : 2500; // 2500 files default
        $file_chunk_max_size = $file_chunk_max_size_str ? self::convert_to_bytes($file_chunk_max_size_str) : 524288000; // 500MB default

        $local_db_parts_path = $folder . '/.disembark-db-parts';
        $db_export_file = $folder . '/database.sql';
        try {
            if (!$skip_db) {
                // --- 3. Database Sync (Always run) ---
                echo "Starting database sync...\n";
                if (!is_dir($local_db_parts_path) && !mkdir($local_db_parts_path, 0755, true)) {
                    throw new \Exception("Could not create temp DB directory.");
                }
                $sql_header = "/*!40101 SET NAMES utf8 */;\nSET sql_mode='NO_AUTO_VALUE_ON_ZERO';\n";
                if (file_put_contents($db_export_file, $sql_header) === false) {
                    throw new \Exception("Could not write to local SQL file.");
                }

                // Fetch the full database list
                $response = \WpOrg\Requests\Requests::get("$siteUrl/wp-json/disembark/v1/database?token=$token", [], ['verify' => false, 'timeout' => 600]);
                if ($response->status_code !== 200 || empty($response->body)) throw new \Exception("Could not get list of database tables.");
                $database = json_decode($response->body);
                if (json_last_error() !== JSON_ERROR_NONE || !is_array($database)) throw new \Exception("Invalid database list received.");
                // Sync always backs up all tables, so we pass the full $database list
                self::processDatabaseBackup($siteUrl, $token, $backup_token, $database, $db_export_file, $local_db_parts_path, $db_max_size, $db_max_rows);
                self::delete_directory($local_db_parts_path); // Clean up temp dir
            } else {
                echo "Skipping database sync as requested.\n";
            }

            if (!$skip_files) {
                // --- 4. File Sync ---
                $files_manifest_chunks = [];
                if ($session_id) {
                    echo "Fetching existing manifest for sync...\n";
                    try {
                        $files_manifest_chunks = self::make_request($siteUrl, $token, $backup_token, '/manifest', [], 'GET');
                        if (!is_array($files_manifest_chunks)) {
                            throw new \Exception("Could not fetch or parse existing manifest. Is the backup ID valid?");
                        }
                        echo "Successfully fetched manifest with " . count($files_manifest_chunks) . " file chunks.\n";
                    } catch (\Exception $e) {
                        echo "Error fetching manifest: {$e->getMessage()}\n";
                        if (!$session_id) {
                            self::cleanupTemporaryFiles($siteUrl, $token, $backup_token);
                        }
                        exit(1);
                    }
                } else {
                    // --- Run generation if no $session_id ---
                    echo "Starting file sync analysis...\n";
                    $include_checksums = (!$is_initial_sync && !$skip_checksums);
                    $files_manifest_chunks = self::runManifestGeneration($siteUrl, $token, $backup_token, $exclude_paths, $include_checksums);
                }

                // Initial Sync Logic (Refactored for Speed & Reliability)
                if ($is_initial_sync) {
                    echo "Performing initial file download...\n";
                    $steps = count($files_manifest_chunks);
                    $current_step = 1;
                    $large_file_threshold = 209715200; // 200MB

                    foreach ($files_manifest_chunks as $file_manifest) {
                        if (!is_object($file_manifest) || !isset($file_manifest->name) || !isset($file_manifest->url)) {
                            $current_step++;
                            continue;
                        }
                        $size = self::humanFilesize($file_manifest->size);
                        // Print initial status
                        $progress_message = sprintf(" - Processing chunk %d/%d (%s)...", $current_step, $steps, $size);
                        echo $progress_message . "\r";

                        // 1. Download Manifest First (Smart Logic)
                        $temp_json_path = $folder . '/' . $file_manifest->name;
                        try {
                            self::download_file_direct($file_manifest->url, $temp_json_path);
                            $chunk_files = json_decode(file_get_contents($temp_json_path));
                            unlink($temp_json_path);
                        } catch (\Exception $e) {
                             echo "\nWarning: Could not download manifest for chunk $current_step. Skipping.\n";
                             $current_step++;
                             continue;
                        }

                        if (!is_array($chunk_files)) {
                             $current_step++;
                             continue;
                        }

                        // 2. Filter Exclusions Locally
                        $files_to_process = [];
                        foreach ($chunk_files as $f) {
                            $is_excluded = false;
                            foreach ($exclude_paths as $exclude_path) {
                                if ($f->name === $exclude_path || strpos($f->name, $exclude_path . '/') === 0) {
                                    $is_excluded = true;
                                    break;
                                }
                            }
                            if (!$is_excluded) {
                                $files_to_process[] = $f;
                            }
                        }

                        if (empty($files_to_process)) {
                            echo $progress_message . " Skipped (All files excluded).\n";
                            $current_step++;
                            continue;
                        }

                        // 3. Split Large vs Small Files
                        $large_files = [];
                        $small_files = [];
                        foreach ($files_to_process as $f) {
                            if (isset($f->size) && $f->size > $large_file_threshold) {
                                $large_files[] = $f;
                            } else {
                                $small_files[] = $f;
                            }
                        }

                        // 4. Download Large Files Directly (Immediately!)
                        foreach ($large_files as $lf) {
                            // Clear the progress line to prevent messy overlap
                            echo str_pad("", 80, " ") . "\r";
                            
                            // We rely on fetch_large_file_publicly to print the "Large file detected" message
                            $local_destination = $folder . '/' . $lf->name;
                            $local_dir = dirname($local_destination);
                            if (!is_dir($local_dir)) @mkdir($local_dir, 0755, true);
                            if (!self::fetch_large_file_publicly($siteUrl, $lf, $local_destination)) {
                                try {
                                    self::download_file_chunked_stream($siteUrl, $token, $lf->name, $local_destination, $lf->size);
                                } catch (\Exception $e) {
                                    echo "     - Failed to download large file {$lf->name}: {$e->getMessage()}\n";
                                }
                            }
                            // Restore the progress message after the large file is done
                            echo $progress_message . "\r";
                        }

                        // 5. Zip remaining small files
                        if (!empty($small_files)) {
                            // Update message to indicate server work
                            echo $progress_message . " (Requesting server-side zip...)\r";
                            
                            try {
                                // Use zip-sync-files to send our filtered list
                                $zip_payload = ['files' => $small_files];
                                $file_url = self::make_request($siteUrl, $token, $backup_token, '/zip-sync-files', $zip_payload, 'POST');
                                
                                if (strpos($file_url, 'http') === 0) {
                                    $file_name = basename($file_url);
                                    $local_zip_chunk_path = $folder . '/' . $file_name;
                                    self::download_file_direct($file_url, $local_zip_chunk_path);
                                    self::unzip_file($local_zip_chunk_path, $folder);
                                    unlink($local_zip_chunk_path);
                                    self::make_request($siteUrl, $token, $backup_token, '/cleanup-file', ['file_name' => $file_name], 'POST');
                                    // Clear line and print Done
                                    echo str_pad("", 80, " ") . "\r";
                                    echo $progress_message . " Done.                          \n";
                                } else {
                                    throw new \Exception("Invalid zip URL received.");
                                }
                            } catch (\Exception $e) {
                                echo "\nWarning: Zip failed for chunk $current_step. Falling back to individual downloads.\n";
                                // Fallback for small files
                                foreach ($small_files as $sf) {
                                     $local_dst = $folder . '/' . $sf->name;
                                     $local_d = dirname($local_dst);
                                     if (!is_dir($local_d)) @mkdir($local_d, 0755, true);
                                     try {
                                         echo "   - Downloading: {$sf->name}\r";
                                         self::download_file_via_stream($siteUrl, $token, $sf->name, $local_dst);
                                     } catch (\Exception $fe) {
                                         echo "\n   - Failed: {$sf->name}\n";
                                     }
                                }
                                echo str_pad("", 80, " ") . "\r";
                            }
                        } else {
                            // If we only had large files, we are done with this chunk
                             echo str_pad("", 80, " ") . "\r";
                             echo $progress_message . " Done.                          \n";
                        }

                        $current_step++;
                    }
                    echo "Initial file sync complete.\n";
                } else {
                    // --- 4b. Subsequent Sync (Diff) ---
                    echo "Fetching remote file manifest...\n";
                    $remote_files_map = [];
                    $all_remote_files = []; 

                    // --- Parallel Manifest Download (Batched) ---
                    $batch_size = 25; // Download 25 chunks at a time
                    $manifest_batches = array_chunk($files_manifest_chunks, $batch_size);
                    $total_batches = count($manifest_batches);
                    $current_batch = 0;

                    foreach ($manifest_batches as $batch) {
                        $current_batch++;
                        echo " - Downloading manifest chunks (Batch $current_batch / $total_batches)...\r";
                        
                        $requests_data = [];
                        foreach ($batch as $file_manifest) {
                            if (isset($file_manifest->url)) {
                                $requests_data[$file_manifest->name] = [
                                    'url' => $file_manifest->url
                                ];
                            }
                        }

                        $request_options = [
                            'verify' => false,
                            'timeout' => 300, 
                            'connect_timeout' => 30,
                        ];

                        try {
                            // Execute parallel requests
                            $responses = \WpOrg\Requests\Requests::request_multiple($requests_data, $request_options);

                            foreach ($responses as $name => $response) {
                                if ($response->success) {
                                    $files = json_decode($response->body);
                                    if (is_array($files)) {
                                        foreach ($files as $file) {
                                            if (isset($file->name)) {
                                                // Filter exclusions
                                                $is_excluded = false;
                                                foreach ($exclude_paths as $exclude_path) {
                                                    if ($file->name === $exclude_path || strpos($file->name, $exclude_path . '/') === 0) {
                                                        $is_excluded = true;
                                                        break;
                                                    }
                                                }
                                                if ($is_excluded) continue;
                                                $remote_files_map[$file->name] = $file;
                                                $all_remote_files[] = $file; 
                                            }
                                        }
                                    }
                                } else {
                                    echo "\nWarning: Failed to download manifest chunk $name. Status: {$response->status_code}\n";
                                }
                            }
                        } catch (\Exception $e) {
                             echo "\nWarning: Batch request failed: " . $e->getMessage() . "\n";
                        }
                    }
                    echo str_pad("", 80, " ") . "\r"; // Clear line

                    echo "Generating local file manifest...\n";
                    $local_files_map = self::generate_local_manifest($folder, $skip_checksums);

                    echo "Comparing manifests and syncing changes...\n";
                    $files_to_download = [];
                    $files_to_delete = [];

                    foreach ($remote_files_map as $path => $remote_file) {
                        $local_file = $local_files_map[$path] ?? null;
                        $should_download = false;
                        if ($skip_checksums) {
                            // --- Smart Checksum (Size Check) ---
                            if (!$local_file || (isset($local_file->size) && isset($remote_file->size) && $local_file->size !== $remote_file->size)) {
                                $should_download = true;
                            }
                        } else {
                            if (!$local_file || !isset($remote_file->checksum) || $local_file->checksum !== $remote_file->checksum) {
                                $should_download = true;
                            }
                        }
                        if ($should_download) $files_to_download[] = $remote_file;
                    }
                    foreach ($local_files_map as $path => $local_file) {
                        if (!isset($remote_files_map[$path])) $files_to_delete[] = $path;
                    }

                    // Download new/changed files
                    if (!empty($files_to_download)) {
                        $total_files_to_download = count($files_to_download);
                        echo " - Syncing $total_files_to_download new/changed file(s)...\n";
                        
                        $file_chunks = [];
                        $current_chunk = [];
                        $current_chunk_size = 0;
                        foreach ($files_to_download as $file) {
                             $fsize = $file->size ?? 0;
                             // Large File Check
                             if ($fsize > 209715200) {
                                 if (!empty($current_chunk)) { $file_chunks[] = $current_chunk; $current_chunk = []; $current_chunk_size = 0; }
                                 // Handle large file immediately
                                 echo str_pad("", 80, " ") . "\r";
                                 // Let fetch_large_file_publicly handle the "Large file detected" text
                                 $local_dest = $folder . '/' . $file->name;
                                 if (!self::fetch_large_file_publicly($siteUrl, $file, $local_dest)) {
                                     self::download_file_chunked_stream($siteUrl, $token, $file->name, $local_dest, $fsize);
                                 }
                                 continue;
                             }
                             
                             if ( ($current_chunk_size + $fsize > $file_chunk_max_size) || (count($current_chunk) >= $file_chunk_size) ) {
                                 $file_chunks[] = $current_chunk;
                                 $current_chunk = [$file];
                                 $current_chunk_size = $fsize;
                             } else {
                                 $current_chunk[] = $file;
                                 $current_chunk_size += $fsize;
                             }
                        }
                        if (!empty($current_chunk)) $file_chunks[] = $current_chunk;
                        $total_chunks = count($file_chunks);
                        foreach ($file_chunks as $i => $chunk) {
                            $chunk_num = $i + 1;
                            // --- FIX: Output Newline (\n) instead of \r ---
                            echo " - Processing sync chunk $chunk_num/$total_chunks (" . count($chunk) . " files)...\n";
                            try {
                                $url = self::make_request($siteUrl, $token, $backup_token, '/zip-sync-files', ['files' => $chunk], 'POST');
                                if (strpos($url, 'http')===0) {
                                    $fname = basename($url);
                                    $lpath = $folder . '/' . $fname;
                                    self::download_file_direct($url, $lpath);
                                    self::unzip_file($lpath, $folder);
                                    unlink($lpath);
                                    self::make_request($siteUrl, $token, $backup_token, '/cleanup-file', ['file_name' => $fname], 'POST');
                                }
                            } catch (\Exception $e) {
                                // Fallback
                                foreach ($chunk as $f) {
                                    $ldest = $folder . '/' . $f->name;
                                    $ldir = dirname($ldest);
                                    if (!is_dir($ldir)) @mkdir($ldir, 0755, true);
                                    self::download_file_via_stream($siteUrl, $token, $f->name, $ldest);
                                }
                            }
                        }
                        echo str_pad("", 80, " ") . "\r";
                        echo " - All sync chunks processed.            \n";
                    } else {
                        echo " - No new or changed files to download.\n";
                    }

                    // Delete files
                    if (!empty($files_to_delete)) {
                        foreach ($files_to_delete as $path) {
                            echo " - Removing: $path\n";
                            $f = $folder . DIRECTORY_SEPARATOR . $path;
                            if (file_exists($f)) unlink($f);
                        }
                    }

                    echo "Cleaning up empty directories...\n";
                    self::delete_empty_dirs($folder);
                    echo "File sync complete.\n";
                }
            } else {
                echo "Skipping file sync as requested.\n";
            }
        } catch (\Exception $e) {
            echo "\nSync failed: {$e->getMessage()}\n";
            if (!$session_id) {
                self::cleanupTemporaryFiles($siteUrl, $token, $backup_token);
            }
            exit(1);
        }

        // --- 5. Final Cleanup ---
        if (!$session_id) {
            self::cleanupTemporaryFiles($siteUrl, $token, $backup_token);
        } else {
            echo "\nSkipping remote cleanup to preserve UI session files.\n";
        }
        echo "\nSync complete: $folder is up to date.\n";
    }

    /**
     * Adds a single file object to the ncdu tree by reference.
     * @param array $root The ncdu tree, passed by reference.
     * @param object $file The file object (must have ->name and ->size).
     * @param array $processed_files Pass-by-ref array for de-duplication
     * @return int Returns 1 if a duplicate was skipped, 2 if a dir (trailing /) was skipped, 3 if a dir-total (conflicting) entry was skipped, 0 otherwise.
     */
    private static function add_file_to_ncdu_tree(&$root, $file, &$processed_files) {
        
        if (empty($file->name) || !isset($file->size)) return 0;
        
        if (substr($file->name, -1) === '/') {
            return 2; 
        }

        if (isset($processed_files[$file->name])) {
            return 1; 
        }
        $processed_files[$file->name] = true; 

        $path = $file->name; 
        $parts = explode('/', $path);
        $filename = array_pop($parts); 
        $file_size = (int)$file->size; 
        
        $node = &$root;
        
        $node['count']++;
        
        $current_parts_path = [];
        
        foreach ($parts as $part) { 
            if (empty($part)) continue;
            if (!isset($node['children'][$part])) { 
                
                $node['children'][$part] = ['name' => $part, 'isdir' => true, 'children' => [], 'asize' => 0, 'dsize' => 0, 'count' => 0];
            } else if ($node['children'][$part]['isdir'] === false) {
                
                
                
                $root['count']--;
                
                
                $temp_node = &$root;
                foreach ($current_parts_path as $parent_part) {
                    if (isset($temp_node['children'][$parent_part])) {
                        $temp_node = &$temp_node['children'][$parent_part];
                        
                        $temp_node['count']--;
                    }
                }
                
                return 0; 
            }

            $node = &$node['children'][$part];
            
            
            $node['count']++;
            $current_parts_path[] = $part; 
        }
        
        if ($filename !== '') { 
            
            
            if (isset($node['children'][$filename]) && $node['children'][$filename]['isdir']) { 
                
                
                
                
                $temp_node = &$root;
                $temp_node['count']--;
                foreach ($parts as $part) {
                    if (isset($temp_node['children'][$part])) { 
                        $temp_node = &$temp_node['children'][$part];
                        
                        $temp_node['count']--;
                    }
                }
                
                return 3; 
            } else {
                
                if (!isset($node['children'][$filename])) {
                    $node['children'][$filename] = ['name' => $filename, 'asize' => $file_size, 'dsize' => $file_size, 'count' => 1, 'isdir' => false];
                }
            }
        }
        return 0; 
    }

    /**
     * Browses a remote site's file system using ncdu.
     */
    private static function ncdu($siteUrl, $session_id = null, $debug = false) {
        // 1. Check for ncdu dependency
        $ncdu_path = trim((string) shell_exec('command -v ncdu'));
        if (empty($ncdu_path)) {
            echo "Error: The 'ncdu' command is not found in your system's PATH.\n";
            echo "Please install ncdu (NCurses Disk Usage) to use this feature.\n";
            exit(1);
        }

        // 2. Authentication and Token Setup
        $siteUrl = rtrim($siteUrl, '/');
        if (!preg_match('/^https?:\/\//', $siteUrl)) {
            $siteUrl = "https://$siteUrl";
        }
        $homeDir = getenv('HOME');
        if (!$homeDir) {
            echo "Error: Unable to determine the home directory.\n";
            exit(1);
        }
        $filePath = $homeDir . '/.disembark';
        if (!file_exists($filePath)) {
            echo "Error: No configuration file found at $filePath.\nPlease run 'disembark connect <site-url> <token>' first.\n";
            exit(1);
        }
        $data = json_decode(file_get_contents($filePath));
        if (!is_array($data)) {
            if (is_object($data)) $data = [$data];
            else {
                echo "Error: Invalid data in $filePath.\n";
                exit(1);
            }
        }
        $token = null;
        foreach ($data as $entry) {
            if (is_object($entry) && isset($entry->siteUrl) && $entry->siteUrl === $siteUrl) {
                $token = $entry->token;
                break;
            }
        }
        if (empty($token)) {
            echo "Error: No token found for $siteUrl.\n";
            exit(1);
        }

        // 3. Backup Token Setup
        $backup_token = "";
        if ($session_id) {
            $backup_token = $session_id;
            echo "Reusing backup session: $backup_token\n";
        } else {
            $backup_token = substr(bin2hex(random_bytes(20)), 0, -28);
        }

        // 4. Fetch Manifest
        $files_manifest_chunks = [];
        try {
            if ($session_id) {
                echo "Fetching existing manifest...\n";
                $files_manifest_chunks = self::make_request($siteUrl, $token, $backup_token, '/manifest', [], 'GET');
            } else {
                echo "Generating new file manifest (this may take a while)...\n";
                $exclude_paths = [];
                $files_manifest_chunks = self::runManifestGeneration($siteUrl, $token, $backup_token, $exclude_paths, false);
            }
            if (!is_array($files_manifest_chunks)) {
                throw new \Exception("Could not fetch or parse manifest. Is the session ID valid?");
            }
        } catch (\Exception $e) {
            echo "Error: {$e->getMessage()}\n";
            if (!$session_id) self::cleanupTemporaryFiles($siteUrl, $token, $backup_token);
            exit(1);
        }

        // 5. Download, Process, and Build Tree
        echo "Processing remote file manifest and building tree...\n";
        
        $ncdu_tree = ['name' => '/', 'isdir' => true, 'children' => [], 'asize' => 0, 'dsize' => 0, 'count' => 0];
        $all_remote_files = []; // Only for debug
        $processed_files = []; // For de-duplication

        if ($debug) {
            echo "Debug mode enabled, will aggregate files in memory for manifest export.\n";
        }

        // --- Batching Logic ---
        $batch_size = 25;
        $manifest_batches = array_chunk($files_manifest_chunks, $batch_size);
        $total_batches = count($manifest_batches);
        $current_batch_num = 0;
        $progress_msg = "";
        $duplicate_count = 0;
        $skipped_slash_dir_count = 0;
        $skipped_total_dir_count = 0;

        try {
            foreach ($manifest_batches as $batch) {
                $current_batch_num++;
                $progress_msg = sprintf("Processing batch %d of %d (downloading %d chunks)...", $current_batch_num, $total_batches, count($batch));
                echo $progress_msg . "\r";

                // Build the request array for request_multiple
                $requests_data = [];
                foreach ($batch as $file_manifest) {
                    if (is_object($file_manifest) && !empty($file_manifest->url) && !empty($file_manifest->name)) {
                        $requests_data[$file_manifest->name] = [
                            'url' => $file_manifest->url
                        ];
                    }
                }

                if (empty($requests_data)) continue;
                
                $request_options = [
                    'verify' => false,
                    'timeout' => 1800, 
                    'connect_timeout' => 30,
                ];

                $responses = \WpOrg\Requests\Requests::request_multiple($requests_data, $request_options);

                foreach ($responses as $name => $response) {
                    if (is_a($response, '\WpOrg\Requests\Response') && $response->success) {
                        $files = json_decode($response->body);
                        if (is_array($files)) {
                            
                            foreach ($files as $file) {
                                if ($debug) {
                                    $all_remote_files[] = $file; 
                                }
                                
                                $result = self::add_file_to_ncdu_tree($ncdu_tree, $file, $processed_files);
                                if ($result === 1) {
                                    $duplicate_count++;
                                } else if ($result === 2) {
                                    $skipped_slash_dir_count++;
                                } else if ($result === 3) {
                                    $skipped_total_dir_count++;
                                }
                            }
                        }
                    } else {
                        $error_msg = is_a($response, '\WpOrg\Requests\Exception') ? $response->getMessage() : "Request failed for $name";
                        echo "\nWarning: Failed to download chunk '$name'. Error: $error_msg\n";
                    }
                }
            }
            echo str_pad("", strlen($progress_msg) + 5, " ") . "\r";
            
        } catch (\Exception $e) {
            echo "Error during batch processing: {$e->getMessage()}\n";
            if (!$session_id) self::cleanupTemporaryFiles($siteUrl, $token, $backup_token);
            exit(1);
        }
        // --- End Batching Logic ---

        if ($skipped_slash_dir_count > 0) {
            echo "Ignored " . number_format($skipped_slash_dir_count) . " directory (trailing /) entries from manifest.\n";
        }
        // Report on skipped directory totals
        if ($skipped_total_dir_count > 0) {
            echo "Ignored " . number_format($skipped_total_dir_count) . " conflicting directory-total entries from manifest.\n";
        }
        if ($duplicate_count > 0) {
            echo "Ignored " . number_format($duplicate_count) . " duplicate file entries from manifest.\n";
        }
        
        if ($debug) {
            $manifest_path = getcwd() . '/.disembark-ncdu-manifest.json';
            file_put_contents($manifest_path, json_encode($all_remote_files, JSON_PRETTY_PRINT));
            echo "Debug: Saved raw manifest to $manifest_path\n";
        }

        // 6. Build the ncdu Tree
        echo "Directory tree build complete.\n";
        $ncdu_json_array = self::format_ncdu_json_array($ncdu_tree);

        // Wrap in the ncdu shell format
        $ncdu_output_data = [
            1, 0, // ncdu JSON format version
            ["progname" => "disembark-cli", "progver" => self::VERSION],
            $ncdu_json_array // The actual tree
        ];
        $json_string = json_encode($ncdu_output_data);

        if ($debug) {
            $input_path = getcwd() . '/.disembark-ncdu-input.json';
            file_put_contents($input_path, $json_string);
            echo "Debug: Saved final ncdu input to $input_path\n";
        }

        // 7. Launch ncdu
        echo "Launching ncdu...\n";
        $descriptors = [
            0 => ["pipe", "r"], // stdin
            1 => STDOUT,        // stdout
            2 => STDERR         // stderr
        ];
        $process = proc_open('ncdu -f -', $descriptors, $pipes);
        if (is_resource($process)) {
            fwrite($pipes[0], $json_string);
            fclose($pipes[0]);
            proc_close($process);
        } else {
            echo "Error: Failed to launch ncdu process.\n";
        }

        // 8. Final Cleanup
        if (!$session_id) {
            self::cleanupTemporaryFiles($siteUrl, $token, $backup_token);
        }
    }

    /**
     * Builds an aggregated associative tree from a flat file list for ncdu.
     */
    private static function build_ncdu_tree($all_remote_files) {
        $root = ['name' => '/', 'isdir' => true, 'children' => [], 'asize' => 0, 'dsize' => 0, 'count' => 0];
        foreach ($all_remote_files as $file) {
            if (empty($file->name) || !isset($file->size)) continue;
            
            $path = rtrim($file->name, '/'); // Keep this fix

            $parts = explode('/', $path);
            $filename = array_pop($parts);
            $file_size = (int)$file->size;
            
            $node = &$root;
            // Add file size all the way up the tree
            $node['asize'] += $file_size;
            $node['dsize'] += $file_size;
            $node['count']++;
            
            foreach ($parts as $part) {
                if (empty($part)) continue;
                if (!isset($node['children'][$part])) {
                    // Create dir node if it doesn't exist
                    $node['children'][$part] = ['name' => $part, 'isdir' => true, 'children' => [], 'asize' => 0, 'dsize' => 0, 'count' => 0];
                }
                $node = &$node['children'][$part];
                // Add file size to this dir node
                $node['asize'] += $file_size;
                $node['dsize'] += $file_size;
                $node['count']++;
            }
            
            // Use ($filename !== '') instead of !empty() to correctly handle files named "0"
            if ($filename !== '') {
                // Add the file node
                // Check if a directory with this name already exists (conflicting path)
                if (isset($node['children'][$filename]) && $node['children'][$filename]['isdir']) {
                    // A directory already exists, this is a conflicting file.
                    // For ncdu's purpose, we'll log it as a special file inside.
                    $conflicting_name = $filename . ' (file)';
                    $node['children'][$conflicting_name] = ['name' => $conflicting_name, 'asize' => $file_size, 'dsize' => $file_size, 'count' => 1, 'isdir' => false];
                } else {
                    // This is the normal case: add the file node
                    $node['children'][$filename] = ['name' => $filename, 'asize' => $file_size, 'dsize' => $file_size, 'count' => 1, 'isdir' => false];
                }
            }
        }
        return $root;
    }

    /**
     * Recursively formats the associative tree into ncdu's expected JSON array format.
     */
    private static function format_ncdu_json_array($node) {
        // 1. Create the node metadata object
        $ncdu_node = [
            'name' => $node['name'],
            'asize' => $node['asize'],
            'dsize' => $node['dsize'],
            'count' => $node['count'],
            'isdir' => $node['isdir']
        ];

        // 2. If it's a FILE, just return the object.
        if (!$node['isdir']) {
            return $ncdu_node;
        }

        // 3. If it's a DIRECTORY, create an array.
        $output = [$ncdu_node]; // Start the array with the dir metadata

        // 4. Process children
        if (!empty($node['children'])) {
            $children = array_values($node['children']);
            
            // Sort children: directories first, then alphabetically
            usort($children, function ($a, $b) {
                if ($a['isdir'] !== $b['isdir']) {
                    return $a['isdir'] ? -1 : 1; // Dirs first
                }
                return strcmp($a['name'], $b['name']); // Then by name
            });
            
            // 5. Add recursive results to the output array
            foreach ($children as $child) {
                // This will append EITHER an OBJECT (for a file) OR an ARRAY (for a dir)
                $output[] = self::format_ncdu_json_array($child); 
            }
        }
        
        // 6. Return the full directory array
        return $output;
    }

    private static function backup($siteUrl, $exclude_paths = [], $exclude_tables = [], $preview = false, $session_id = null, $db_max_size_str = null, $db_max_rows_str = null, $skip_db = false, $skip_files = false, $token = null) {

        // Trim trailing slashes from the site URL
        $siteUrl = rtrim($siteUrl, '/');
        // Verify the site URL starts with http:// or https://
        if (!preg_match('/^https?:\/\//', $siteUrl)) {
            $siteUrl = "https://$siteUrl";
            echo "The site URL must start with http:// or https://. Attempting to use $siteUrl\n";
        }

        if ($token === null) {

            $homeDir = getenv('HOME');
            if (!$homeDir) {
                echo "Error: Unable to determine the home directory.\n";
                exit(1);
            }

            $filePath = $homeDir . '/.disembark';
            $data = [];
            // Check if the file already exists and read its contents
            if (file_exists($filePath)) {
                $jsonContents = file_get_contents($filePath);
                $data = json_decode($jsonContents);
                if (!is_array($data)) {
                    if (is_object($data)) {
                        $data = [$data];
                    } else {
                        echo "Error: Invalid data in $filePath.\n";
                        exit(1);
                    }
                }
            } else {
                echo "Error: No configuration file found at $filePath.\nPlease run 'disembark connect <site-url> <token>' first.\n";
                exit(1);
            }
        

            // Find the token for the given siteUrl
            $token = null;
            foreach ($data as $entry) {
                if (is_object($entry) && isset($entry->siteUrl) && $entry->siteUrl === $siteUrl) {
                    $token = $entry->token;
                    break;
                }
            }

            if (empty($token)) {
                echo "Error: No token found for $siteUrl.\nRun 'disembark connect $siteUrl <token>' to configure.\n";
                exit(1);
            }

        }

        $files = [];
        if ($session_id) {
            $backup_token = $session_id;

            $all_remote_files = [];
            $client_side_filtering = false;

            echo "Reusing backup session: $backup_token\n";

            try {
                echo "Fetching existing manifest...\n";
                // Use the new /manifest GET endpoint
                $files = self::make_request($siteUrl, $token, $backup_token, '/manifest', [], 'GET');
                if (!is_array($files)) {
                    throw new \Exception("Could not fetch or parse existing manifest. Is the backup ID valid or is the manifest still generating?");
                }
                echo "Successfully fetched manifest with " .
                    count($files) . " file chunks.\n";

                if (!empty($exclude_paths)) {
                    // We only apply client-side filtering if exclusions are *actually* passed with a session-id
                    $client_side_filtering = true;
                    echo "Applying client-side exclusions to session manifest...\n";

                    // 1. Download all manifest JSONs
                    $temp_manifest_dir = rtrim(sys_get_temp_dir(), DIRECTORY_SEPARATOR) .
                        '/disembark-manifests-' . $backup_token;
                    if (!is_dir($temp_manifest_dir) && !mkdir($temp_manifest_dir, 0755, true)) {
                        throw new \Exception("Could not create temp manifest dir for filtering.");
                    }

                    $total_chunks_to_fetch = count($files);
                    $fetched_chunks = 0;
                    foreach ($files as $file_manifest) {
                        $fetched_chunks++;
                        echo sprintf(" - Downloading manifest chunk %d/%d...\r", $fetched_chunks, $total_chunks_to_fetch);
                        $chunk_url = $file_manifest->url;
                        $local_chunk_path = $temp_manifest_dir . '/' . $file_manifest->name;
                        self::download_file_direct($chunk_url, $local_chunk_path);
                        $chunk_json = file_get_contents($local_chunk_path);
                        unlink($local_chunk_path);
                        $chunk_files = json_decode($chunk_json);
                        if (is_array($chunk_files)) {
                            $all_remote_files = array_merge($all_remote_files, $chunk_files);
                        }
                    }
                    self::delete_directory($temp_manifest_dir);
                    echo str_pad("", 80, " ") . "\r"; // Clear line

                    // 2. Filter the aggregated file list
                    $filtered_files = [];
                    foreach ($all_remote_files as $file) {
                        if (!is_object($file) || empty($file->name)) continue;
                        $is_excluded = false;
                        foreach ($exclude_paths as $exclude_path) {
                            if ($file->name === $exclude_path || strpos($file->name, $exclude_path . '/') === 0) {
                                $is_excluded = true;
                                break;
                            }
                        }

                        if (!$is_excluded) {
                            $filtered_files[] = $file;
                        }
                    }
                }

                // 3. Display correct summary
                self::displayBackupSummary($siteUrl, $token, $client_side_filtering ? [] : $files, $exclude_tables);
                // Pass empty files manifest if we filtered, as we'll override
                if ($client_side_filtering) {
                    echo "\n--- Client-side File Filter Summary ---\n";
                    printf("%-24s %12s %12s\n", "Original Session Files:", number_format(count($all_remote_files)), self::humanFilesize(array_sum(array_column($all_remote_files, 'size'))));
                    printf("%-24s %12s %12s\n", "Files after Exclusions:", number_format(count($filtered_files)), self::humanFilesize(array_sum(array_column($filtered_files, 'size'))));
                    echo "-----------------------------------------\n";
                } elseif (!empty($exclude_tables)) {
                    echo "* Database exclusion summary reflects the pre-generated manifest; local --exclude-tables flag is ignored.\n";
                }
            } catch (\Exception $e) {
                echo "Error fetching manifest: {$e->getMessage()}\n";
                // Do NOT clean up, it's not our session
                exit(1);
            }
        } else {
            if (!$skip_files) {
                // Generate unique token for this backup session
                $backup_token = substr(bin2hex(random_bytes(20)), 0, -28);
                $client_side_filtering = false;
                // Run preview, which now also generates the manifest for the actual backup
                $files = self::runPreview($siteUrl, $token, $backup_token, $exclude_paths, $exclude_tables);
            } else {
                // Still need a token for the DB summary
                $backup_token = substr(bin2hex(random_bytes(20)), 0, -28);
                $client_side_filtering = false;
                $files = []; // Empty files
                self::displayBackupSummary($siteUrl, $token, $files, $exclude_tables);
                echo "Skipping file analysis as requested.\n";
            }
        }

        if (!empty($exclude_paths)) {
            echo "Excluding the following paths during backup:\n";
            foreach ($exclude_paths as $path) {
                echo " - $path\n";
            }
        }
        if (!empty($exclude_tables)) {
            echo "Excluding database tables matching:\n";
            foreach ($exclude_tables as $pattern) {
                echo " - $pattern\n";
            }
        }

        // --- Setup Local Backup Environment ---
        // Convert DB threshold arguments, using defaults if not provided
        $db_max_size = $db_max_size_str ?
            self::convert_to_bytes($db_max_size_str) : 209715200; // 200MB default
        $db_max_rows = $db_max_rows_str ? (int)$db_max_rows_str : 1000000;
        // 1M rows default

        echo "Starting backup for $siteUrl using backup token $backup_token\n";
        // --- Setup Local Backup Environment ---
        // Create the directory name
        $temp_directory_name = "snapshot-" .
            time();
        // Use getcwd() to create a full, absolute path
        $temp_directory = getcwd() .
            DIRECTORY_SEPARATOR . $temp_directory_name;

        $local_db_path = $temp_directory . '/database';
        $local_public_path = $temp_directory . '/public';
        $domain = preg_replace('/^https?:\/\/(www\.)?/', '', $siteUrl);
        $domain = preg_replace('/\//', '_', $domain);
        $db_export_file = $local_public_path . '/database-' . $temp_directory_name . '.sql';
        $final_zip_name = "{$temp_directory_name}-{$domain}.zip";
        try {
            if (!mkdir($temp_directory, 0755, true)) throw new \Exception("Could not create temp directory $temp_directory.");
            if (!$skip_db) {
                if (!mkdir($local_db_path, 0755, true)) throw new \Exception("Could not create temp directory $local_db_path.");
            }
            if (!mkdir($local_public_path, 0755, true)) throw new \Exception("Could not create temp directory $local_public_path.");
            if (!$skip_db) {
                // Write SQL headers
                $sql_header = "/*!40101 SET NAMES utf8 */;\nSET sql_mode='NO_AUTO_VALUE_ON_ZERO';\n";
                if (file_put_contents($db_export_file, $sql_header) === false) {
                    throw new \Exception("Could not write to local SQL file $db_export_file.");
                }
            }
            echo "Created local temporary directory at $temp_directory\n";
            // --- END Local Setup ---

            if (!$skip_db) {
                // --- Database Backup ---
                $database = [];
                try {
                    // Fetch full table list
                    $response = \WpOrg\Requests\Requests::get("$siteUrl/wp-json/disembark/v1/database?token=$token", [], ['verify' => false, 'timeout' => 600]);
                    if ($response->status_code !== 200 || empty($response->body)) {
                        throw new \Exception("Could not get list of database tables. Status: " . $response->status_code);
                    }
                    $all_tables = json_decode($response->body);
                    if (json_last_error() !== JSON_ERROR_NONE || !is_array($all_tables)) {
                        throw new \Exception("Invalid database list received during backup.");
                    }

                    // Filter tables based on exclusions
                    if (!empty($exclude_tables)) {
                        foreach ($all_tables as $table) {
                         
                            $is_excluded = false;
                            foreach ($exclude_tables as $pattern) {
                                if (fnmatch($pattern, $table->table)) {
                                    $is_excluded = true;
                                    break;
                                }
                            }
                            if (!$is_excluded) {
                                $database[] = $table;
                            }
                        }
                    } else {
                       
                         $database = $all_tables; // No exclusions, use all tables
                    }
                } catch (\Exception $e) {
                    echo "Error during database preparation: {$e->getMessage()}\n";
                    throw $e; 
                }

                if (!empty($database)) {
                    // Call the new helper function with the *filtered* list
                    self::processDatabaseBackup($siteUrl, $token, $backup_token, $database, $db_export_file, $local_db_path, $db_max_size, $db_max_rows);
                } else {
                    echo "No database tables to back up (all were excluded or list is empty).\n";
                }

                rmdir($local_db_path);
                // Remove empty database temp dir
            } else {
                echo "Skipping database backup as requested.\n";
            }
            
            if (!$skip_files) {
                // --- File Zipping ---
                if (!$client_side_filtering) {
                    // Process server-generated manifest chunks
                    if (!empty($files)) {
  
                        $steps = count($files);
                        $current_step = 1;
                        $total_file_count = array_sum(array_column($files, 'count'));
                        $total_file_size = self::humanFilesize(array_sum(array_column($files, 'size')));
                        echo "Preparing to backup " . number_format($total_file_count) .
                            " files totaling " . $total_file_size . "\n";
                        $exclude_files_string = implode("\n", $exclude_paths);
                        $zip_payload_base = [
                            "token" => $token,
                            "backup_token" => $backup_token,
                            "exclude_files" => $exclude_files_string,
        
                        ];
                        foreach ($files as $file_manifest) {
                            // Check for URL from manifest
                            if (!is_object($file_manifest) || !isset($file_manifest->name) || !isset($file_manifest->url)) {
                             
                                echo "Warning: Skipping invalid manifest chunk data in zipping loop.\n";
                                $current_step++;
                                continue;
                            }

                            $size = self::humanFilesize($file_manifest->size);
                            $progress_message = sprintf(" - Zipping and downloading chunk %d/%d: %s files totaling %s", $current_step, $steps, number_format($file_manifest->count), $size);
                            echo $progress_message .
                                "...\r";

                            $zip_payload = $zip_payload_base;
                            $zip_payload['file'] = $file_manifest->name;

                            // 1. Zip (now returns a full URL)
                            $file_url = self::make_request($siteUrl, $token, $backup_token, '/zip-files', $zip_payload, 'POST');
                            if (strpos($file_url, 'http') !== 0) {
                                throw new \Exception("Zip failed, did not receive a valid URL. Got: $file_url");
                            }
                            $file_name = basename($file_url);
                            $local_file_path = $temp_directory . '/' . $file_name;

                            // 2. Download (use new direct download function)
                            self::download_file_direct($file_url, $local_file_path);
                            // 3. Unzip locally
                            self::unzip_file($local_file_path, $local_public_path);
                            unlink($local_file_path); // Delete local zip chunk

                            // 4. Clean up remote zip chunk
                            self::make_request($siteUrl, $token, $backup_token, '/cleanup-file', ['file_name' => $file_name], 'POST');
                            echo $progress_message . " - Done.\n";
                            $current_step++;
                            usleep(100000);
                        }
                        echo "File zipping and download complete.\n";
                    } else {
                        echo "Skipping file backup as no files were included in the manifest.\n";
                    }
                } else {
                    // Process client-side filtered file list
                    echo "Starting client-side filtered file backup...\n";
                    // 1. Re-chunk $filtered_files (which was populated in the --session-id block)
                    $file_chunks = [];
                    $current_chunk = [];
                    $current_chunk_size = 0;
                    // Use sync's defaults
                    $file_chunk_size = 2500;
                    $file_chunk_max_size = 524288000; // 500MB

                    foreach ($filtered_files as $file) {
                        $file_size = isset($file->size) && is_numeric($file->size) ?
                            (int)$file->size : 0;
                        if ($file_size > $file_chunk_max_size) {
                            if (!empty($current_chunk)) $file_chunks[] = $current_chunk;
                            $file_chunks[] = [$file];
                            $current_chunk = [];
                            $current_chunk_size = 0;
                            continue;
                        }
                        if (
                            (!empty($current_chunk) && $current_chunk_size + $file_size > $file_chunk_max_size) ||
                            (count($current_chunk) >= $file_chunk_size)
                        ) {
     
                            $file_chunks[] = $current_chunk;
                            $current_chunk = [$file];
                            $current_chunk_size = $file_size;
                        } else {
                            $current_chunk[] = $file;
                            $current_chunk_size += $file_size;
                        }
                    }
                    if (!empty($current_chunk)) $file_chunks[] = $current_chunk;
                    // 2. Process new chunks
                    $total_chunks = count($file_chunks);
                    $current_chunk_num = 0;
                    foreach ($file_chunks as $chunk) {
                        $current_chunk_num++;
                        $chunk_file_count = count($chunk);
                        $chunk_total_size = self::humanFilesize(array_sum(array_column($chunk, 'size')));
                        $progress_message = sprintf(" - Zipping and downloading filtered chunk %d/%d (%d files, %s)", $current_chunk_num, $total_chunks, $chunk_file_count, $chunk_total_size);
                        echo $progress_message . "...\r";

                        $file_url = null;
                        $file_name = null;
                        $local_zip_chunk_path = null;
                        try {
                            // Call /zip-sync-files
                            $file_url = self::make_request($siteUrl, $token, $backup_token, '/zip-sync-files', ['files' => $chunk], 'POST');
                            if (strpos($file_url, 'http') !== 0) {
                                throw new \Exception("Sync zip for chunk $current_chunk_num failed. Got: $file_url");
                            }

                            $file_name = basename($file_url);
                            $local_zip_chunk_path = $temp_directory . '/' . $file_name;

                            self::download_file_direct($file_url, $local_zip_chunk_path);
                            self::unzip_file($local_zip_chunk_path, $local_public_path);
                            unlink($local_zip_chunk_path);

                            self::make_request($siteUrl, $token, $backup_token, '/cleanup-file', ['file_name' => $file_name], 'POST');
                            echo $progress_message . " - Done.        \n";
                        } catch (\Exception $e) {
                            echo "\nWarning: Failed to process chunk $current_chunk_num: {$e->getMessage()}\n";
                            if ($local_zip_chunk_path && file_exists($local_zip_chunk_path)) unlink($local_zip_chunk_path);
                            if ($file_name) {
                                self::make_request($siteUrl, $token, $backup_token, '/cleanup-file', ['file_name' => $file_name], 'POST');
                            }
                            // We'll just skip this chunk and continue
                        }
                    }
                    echo "Filtered file zipping and download complete.\n";
                }
                // --- End File Zipping ---
            } else {
                echo "Skipping file backup as requested.\n";
            }

            // --- Final Local Zipping ---
            echo "Generating final local zip file: $final_zip_name...\n";
            self::zip_directory($local_public_path, $final_zip_name);
            echo "Successfully created $final_zip_name\n";
        } catch (\Exception $e) {
            // Catch any exception thrown during the backup process
            echo "\nBackup failed: {$e->getMessage()}\n";
            echo "Partial files may be left in {$temp_directory}\n";
            // Attempt remote cleanup even if backup failed, but only if it's not a reused session
            if (!$session_id) {
                self::cleanupTemporaryFiles($siteUrl, $token, $backup_token);
            }
            exit(1);
            // Exit with error status
        }

        // --- Final Cleanup ---
        try {
            echo "Cleaning up local temporary files...\n";
            self::delete_directory($temp_directory);
        } catch (\Exception $e) {
            echo "\nWarning: Failed to clean up local directory {$temp_directory}: {$e->getMessage()}\n";
        }

        // Final remote cleanup, only if it's not a reused session
        if (!$session_id) {
            self::cleanupTemporaryFiles($siteUrl, $token, $backup_token);
        } else {
            echo "\nSkipping remote cleanup to preserve UI session files.\n";
        }
        echo "\nBackup complete: $final_zip_name is ready.\n";
    }

    private static function sites() {
        $homeDir = getenv('HOME');
        if (!$homeDir) {
            echo "Error: Unable to determine the home directory.\n";
            exit(1);
        }

        $filePath = $homeDir . '/.disembark';
        $data = [];
        if (file_exists($filePath)) {
            $jsonContents = file_get_contents($filePath);
            $data = json_decode($jsonContents);
            if (!is_array($data)) {
                if (is_object($data)) {
                    $data = [$data];
                } else {
                    echo "Error: Invalid data in $filePath.\n";
                    exit(1);
                }
            }
        } else {
            echo "No configuration file found at $filePath. No sites connected.\n";
            exit(0);
        }

        if (empty($data)) {
            echo "No sites connected.\n";
        } else {
            echo "Connected sites:\n";
            foreach ($data as $entry) {
                if (is_object($entry) && isset($entry->siteUrl)) {
                    echo "- {$entry->siteUrl}\n";
                } else {
                    echo "- (Invalid entry in config file)\n";
                }
            }
        }
    }

    private static function version() {
        $version = self::VERSION;
        echo "Disembark CLI v{$version}\n";
    }

    private static function upgrade() {
        echo "Checking for updates...\n";
        $current_version = self::VERSION;

        $latest_version_cmd = "curl -sL -o /dev/null -w '%{url_effective}' https://github.com/DisembarkHost/disembark-cli/releases/latest | sed 's#.*/v##'";
        $latest_version = trim(shell_exec($latest_version_cmd));
        if (empty($latest_version) || !preg_match('/^\d+\.\d+\.\d+/', $latest_version)) {
            echo "Error: Could not fetch the latest version information or invalid version format received ('{$latest_version}').\n";
            exit(1);
        }

        if (version_compare($latest_version, $current_version, '>')) {
            echo "New version {$latest_version} available. Upgrading from {$current_version}...\n";
            $pharPath = \Phar::running(false);
            if (empty($pharPath)) {
                $scriptPath = realpath($_SERVER['argv'][0]);
                if ($scriptPath && is_file($scriptPath)) {
                    $pharPath = $scriptPath;
                    echo "Info: Determined script path as {$pharPath}.\n";
                } else {
                    echo "Error: Could not determine the path of the running script. Upgrade failed.\n";
                    echo "Please download the latest version manually from:\n";
                    echo "https://github.com/DisembarkHost/disembark-cli/releases/latest/download/disembark.phar\n";
                    exit(1);
                }
            }

            $downloadUrl = 'https://github.com/DisembarkHost/disembark-cli/releases/latest/download/disembark.phar';
            $tmpFile = tempnam(sys_get_temp_dir(), 'disembark-upgrade-');
            if ($tmpFile === false) {
                echo "Error: Could not create a temporary file. Upgrade failed.\n";
                exit(1);
            }

            echo "Downloading new version from {$downloadUrl}...\n";
            $download_cmd = sprintf("curl -sL '%s' -o '%s'", $downloadUrl, $tmpFile);
            shell_exec($download_cmd);
            if (!file_exists($tmpFile) || filesize($tmpFile) === 0) {
                echo "Error: Failed to download the new version. File is empty or does not exist at {$tmpFile}. Upgrade failed.\n";
                if (file_exists($tmpFile)) unlink($tmpFile);
                exit(1);
            }

            chmod($tmpFile, 0755);
            $move_cmd = sprintf("mv '%s' '%s'", $tmpFile, $pharPath);
            exec($move_cmd, $output, $return_var);
            if ($return_var !== 0) {
                echo "Error: Failed to replace the current script at {$pharPath}.\n";
                echo "You might need to run the command with sufficient permissions (e.g., using sudo):\n";
                echo "sudo disembark upgrade\n";
                if (file_exists($tmpFile)) {
                    unlink($tmpFile);
                }
                exit(1);
            }


            echo "Upgrade complete. You are now on version {$latest_version}.\n";
        } else {
            echo "You are already using the latest version ({$current_version}).\n";
        }
    }

    private static function showHelp() {
        echo "Disembark CLI\n";
        echo "\n";
        echo "Usage:\n";
        echo "  disembark backup <site-url> [options]\n";
        echo "  disembark sync <site-url> [<folder>] [options]\n";
        echo "  disembark <command>\n";
        echo "\n";
        echo "Primary Commands:\n";
        echo "\n";
        echo "  disembark backup <site-url> [options]\n";
        echo "    Initiate a backup for a connected site.\n";
        echo "\n";
        echo "    Options for backup:\n";
        echo "      --preview                          Show a summary of files and DB tables to be backed up without running the backup.\n";
        echo "      --skip-db                          Skip the database backup and only process files.\n";
        echo "      --skip-files                       Skip the file backup and only process the database.\n";
        echo "      --skip-checksums                   Skip file integrity checks. Only downloads files missing from destination.\n";
        echo "      -x <path>                          Exclude a file or directory path (e.g., wp-content/cache). Can be specified multiple times.\n";
        echo "      --exclude-tables=<tables>          Exclude specific database tables (comma-separated, no spaces). Wildcards (*) are supported.\n";
        echo "      --db-max-size=<size>               Set max DB part size (e.g., 25MB, 1G). Default: 200MB.\n";
        echo "      --db-max-rows=<num>                Set max DB part rows (e.g., 100000). Default: 1000000.\n";
        echo "      --session-id=<id>                  Reuse a specific backup session ID (backup token) generated by the plugin UI.\n";
        echo "\n";
        echo "  disembark sync <site-url> [<folder>] [options]\n";
        echo "    Create or update a local mirror of the site.\n";
        echo "\n";
        echo "    Options for sync:\n";
        echo "      --debug                            Save local and remote manifest files for debugging.\n";
        echo "      --skip-db                          Skip the database sync and only process files.\n";
        echo "      --skip-files                       Skip the file sync and only process the database.\n";
        echo "      --db-max-size=<size>               Set max DB part size (e.g., 25MB, 1G). Default: 200MB.\n";
        echo "      --db-max-rows=<num>                Set max DB part rows (e.g., 100000). Default: 1000000.\n";
        echo "      --file-chunk-size=<num>            Set number of files per sync zip. Default: 2500.\n";
        echo "      --file-chunk-max-size=<size>       Set max total size per sync zip (e.g., 100MB). Default: 500MB.\n";
        echo "      --session-id=<id>                  Reuse a backup session ID from the UI.\n";
        echo "\n";
        echo "  disembark ncdu <site-url> [options]\n";
        echo "    Browse the remote site's file system interactively using ncdu.\n";
        echo "\n";
        echo "    Options for ncdu:\n";
        echo "      --session-id=<id>                  Reuse a backup session ID from the UI to load its manifest.\n";
        echo "      --debug                            Save raw manifest and ncdu input files locally for debugging.\n";
        echo "\n";
        echo "Other Commands:\n";
        echo "  disembark connect <site-url> <token>   Connect to a site and save its token.\n";
        echo "  disembark list                         List all sites currently connected.\n";
        echo "  disembark upgrade                      Upgrade the Disembark CLI tool to the latest version.\n";
        echo "  disembark version                      Show the current version of the Disembark CLI tool.\n";
        echo "\n";
        echo "Example:\n";
        echo "  disembark backup https://example.com --preview -x wp-content/uploads/large-dir --exclude-tables=wp_options,wp_logs\n";
        echo "  disembark backup https://example.com --session-id=a1b2c3d4e5f6\n";
        echo "  disembark sync https://example.com --session-id=a1b2c3d4e5f6 --skip-db\n";
    }

    private static function convert_to_bytes($size_str) {
        $size_str = strtolower(trim($size_str));
        
        // Use preg_match to separate the number and the unit
        preg_match('/^([0-9\.]+)\s*(kb|mb|gb|k|m|g)?$/', $size_str, $matches);
        
        $value = isset($matches[1]) ? (float) $matches[1] : 0;
        $unit = isset($matches[2]) ? $matches[2] : '';

        switch ($unit) {
            case 'g':
            case 'gb':
                $value *= 1024 * 1024 * 1024;
                break;
            case 'm':
            case 'mb':
                $value *= 1024 * 1024;
                break;
            case 'k':
            case 'kb':
                $value *= 1024;
                break;
        }
        return (int) $value;
    }

    /**
     * Convert bytes to human-readable format.
     */
    private static function humanFilesize($bytes, $decimals = 2) {
        if ($bytes === null) return '0 B';
        if (!is_numeric($bytes)) return 'N/A';

        $bytesNum = (float) $bytes;

        if ($bytesNum == 0) return '0 B';

        $factor = floor(log($bytesNum, 1024));
        $sz = 'BKMGTP';
        $max_factor = strlen($sz) - 1;

        $factor = max(0, min((int)$factor, $max_factor));

        $size_str = sprintf("%.{$decimals}f", $bytesNum / pow(1024, $factor));
        $unit = $sz[$factor];
        $suffix = ($factor > 0) ? 'B' : '';

        return $size_str . ' ' . $unit . $suffix;
    }

    /**
     * Downloads a file using native cURL with a progress bar.
     */
    private static function download_file_direct($url, $destination) {
        $fp = fopen($destination, 'w+');
        if ($fp === false) {
            throw new \Exception("Could not open $destination for writing");
        }

        $ch = curl_init($url);
        curl_setopt($ch, CURLOPT_FILE, $fp);
        curl_setopt($ch, CURLOPT_TIMEOUT, 3600); // 1 hour timeout
        curl_setopt($ch, CURLOPT_SSL_VERIFYPEER, false);
        curl_setopt($ch, CURLOPT_FOLLOWLOCATION, true);
        
        // Enable Progress Bar
        curl_setopt($ch, CURLOPT_NOPROGRESS, false);
        curl_setopt($ch, CURLOPT_PROGRESSFUNCTION, function(
            $resource, 
            $download_size, 
            $downloaded, 
            $upload_size, 
            $uploaded
        ) {
            if ($download_size > 0) {
                $percent = round(($downloaded / $download_size) * 100);
                $downloaded_human = self::humanFilesize($downloaded);
                $total_human = self::humanFilesize($download_size);
                
                // \r keeps overwriting the same line
                echo str_pad("", 80, " ") . "\r"; 
                echo "     - Downloading: $downloaded_human / $total_human ($percent%)...\r";
            }
        });

        $data = curl_exec($ch);
        $error = curl_error($ch);
        $statusCode = curl_getinfo($ch, CURLINFO_HTTP_CODE);
        
        curl_close($ch);
        fclose($fp);

        // Clear the progress line
        echo str_pad("", 80, " ") . "\r";

        if (!$data) {
            throw new \Exception("cURL Download Error: $error");
        }

        if ($statusCode >= 400) {
            throw new \Exception("HTTP Error $statusCode");
        }
    }

    /**
     * Downloads a file from the /stream-file endpoint using WpOrg\Requests.
     */
    private static function download_file_via_stream($siteUrl, $token, $relative_path, $destination) {
        $attempts = 0;
        $max_attempts = 3;
        $last_error = "";

        while ($attempts < $max_attempts) {
            $attempts++;
            try {
                $endpoint_url = $siteUrl . '/wp-json/disembark/v1/stream-file';
                $payload = json_encode(['token' => $token, 'file' => $relative_path]);
                $headers = ['Content-Type' => 'application/json'];
                // Fetch response into memory, DO NOT stream to file
                $options = [
                    'verify' => false,
                    'timeout' => 1800,
                    'connect_timeout' => 30,
                ];
                $response = \WpOrg\Requests\Requests::post($endpoint_url, $headers, $payload, $options);
                if (!$response->success) {
                    // Add response body to the error for debugging
                    if ($response->status_code == 404 || $response->status_code == 403) {
                        throw new \Exception("Stream API failed: HTTP {$response->status_code}. Body: " . substr($response->body, 0, 200));
                    }
                    throw new \Exception("Stream API request failed with status code: {$response->status_code}. Body: " . substr($response->body, 0, 200));
                }

                // Manually write the response body to the file
                if (file_put_contents($destination, $response->body) === false) {
                    throw new \Exception("Failed to write downloaded stream content to $destination.");
                }

                return;
                // Success

            } catch (\Exception $e) {
                echo "\nWarning: Failed to stream $relative_path (Attempt $attempts/$max_attempts): {$e->getMessage()}\n";
                $last_error = $e->getMessage();
                if (file_exists($destination)) unlink($destination);
                if ($attempts < $max_attempts) {
                    echo "Retrying in 2 seconds...\n";
                    sleep(2);
                }
            }
        }

        // If loop finishes, streaming failed.
        throw new \Exception("Stream failed after $max_attempts attempts. Last error: $last_error");
    }

    /**
     * Downloads a database export file, trying direct download first and falling back to stream.
     */
    private static function download_db_file($siteUrl, $token, $relative_path, $destination) {
        // --- 1. Construct Direct URL ---
        // The relative path is already the full path from the WP root, e.g., wp-content/uploads/disembark/token/file.sql.txt
        // We need to URL-encode the components
        $path_parts = explode('/', $relative_path);
        $encoded_parts = array_map('rawurlencode', $path_parts);
        $encoded_relative_path = implode('/', $encoded_parts);
        $direct_url = $siteUrl . '/' . $encoded_relative_path;

        // --- 2. Try Direct Download First ---
        try {
            self::download_file_direct($direct_url, $destination);
            // If it succeeds, just return.
            return;
        } catch (\Exception $e) {
            echo "\nWarning: Direct download failed for '$relative_path': {$e->getMessage()}\n";
            echo "Attempting to download via stream API as fallback...\n";
        }

        // --- 3. Fallback to Stream API ---
        try {
            self::download_file_via_stream($siteUrl, $token, $relative_path, $destination);
            echo "Stream API download successful for: $relative_path\n";
        } catch (\Exception $e) {
            // Both methods failed. This is a fatal error for this file.
            echo "\nStream API fallback also failed: {$e->getMessage()}\n";
            throw new \Exception("Failed to download '$relative_path' using both direct and stream methods.");
        }
    }

    /**
     * Generates a local manifest of files.
     */
    private static function generate_local_manifest($dir, $skip_checksums = false) {
        $files_map = [];
        $real_root = realpath($dir);
        if ($real_root === false) return [];

        $iterator = new \RecursiveIteratorIterator(
            new \RecursiveDirectoryIterator($real_root, \RecursiveDirectoryIterator::SKIP_DOTS),
            \RecursiveIteratorIterator::SELF_FIRST
        );
        foreach ($iterator as $file) {
            if ($file->isDir()) continue;
            $path = $file->getRealPath();
            $relative_path = ltrim(substr($path, strlen($real_root)), DIRECTORY_SEPARATOR);

            // Skip sync-specific files
            if ($relative_path === 'database.sql' ||
                $relative_path === 'db_export.sql' ||
                strpos($relative_path, '.disembark-db-parts') === 0 ||
                strpos($relative_path, '.disembark-manifests') === 0) {
                continue;
            }

            // Skip expensive MD5 calc if requested
            $checksum = ($skip_checksums) ? null : md5_file($path);

            $files_map[$relative_path] = (object) [
                'name' => $relative_path,
                'size' => $file->getSize(),
                'checksum' => $checksum
            ];
        }
        return $files_map;
    }

    /**
     * Recursively deletes empty directories.
     */
    private static function delete_empty_dirs($dir) {
        if (!is_dir($dir)) return;
        $iterator = new \RecursiveIteratorIterator(new \RecursiveDirectoryIterator($dir, \RecursiveDirectoryIterator::SKIP_DOTS), \RecursiveIteratorIterator::CHILD_FIRST);
        foreach ($iterator as $file) {
            if ($file->isDir() && !(new \FilesystemIterator($file->getPathname()))->valid()) {
                rmdir($file->getPathname());
            }
        }
    }

    /**
     * Unzips a file to a destination.
     */
    private static function unzip_file($file, $destination) {
        if (!class_exists('ZipArchive')) {
            echo "\nError: ZipArchive PHP extension is required to unpack files locally. Backup failed.\n";
            throw new \Exception('ZipArchive not found.');
        }
        $zip = new \ZipArchive;
        if ($zip->open($file) === TRUE) {
            if ($zip->extractTo($destination) === FALSE) {
                $zip->close();
                throw new \Exception("Failed to extract $file to $destination.");
            }
            $zip->close();
        } else {
            echo "\nError: Failed to open local zip archive $file. Backup failed.\n";
            throw new \Exception("Failed to open $file.");
        }
    }

    /**
     * Zips a directory into a single archive.
     */
    private static function zip_directory($source, $destination) {
        if (!class_exists('ZipArchive')) {
            throw new \Exception('ZipArchive PHP extension is required to create the final zip.');
        }
        $zip = new \ZipArchive();
        if (!$zip->open($destination, \ZipArchive::CREATE | \ZipArchive::OVERWRITE)) {
            throw new \Exception("Failed to create zip archive at $destination.");
        }

        $source = realpath($source);
        if ($source === false) {
            throw new \Exception("Source directory $source does not exist.");
        }

        $files = new \RecursiveIteratorIterator(
            new \RecursiveDirectoryIterator($source, \RecursiveDirectoryIterator::SKIP_DOTS),
            \RecursiveIteratorIterator::SELF_FIRST
        );
        // Add the root 'public' directory itself
        $zip->addEmptyDir('public');
        foreach ($files as $file) {
            $file = realpath($file);
            // Get relative path for root of zip
            $relativePath = 'public' . DIRECTORY_SEPARATOR . substr($file, strlen($source) + 1);

            if (empty($relativePath)) continue; // Skip the root folder itself

            if (is_dir($file)) {
                $zip->addEmptyDir($relativePath);
            } else if (is_file($file)) {
                $zip->addFile($file, $relativePath);
            }
        }
        $zip->close();
    }

    /**
     * Recursively deletes a directory.
     */
    private static function delete_directory($dir) {
        if (!is_dir($dir)) {
            return;
        }
        $it = new \RecursiveDirectoryIterator($dir, \RecursiveDirectoryIterator::SKIP_DOTS);
        $files = new \RecursiveIteratorIterator($it, \RecursiveIteratorIterator::CHILD_FIRST);
        foreach ($files as $file) {
            if ($file->isDir()) {
                rmdir($file->getRealPath());
            } else {
                unlink($file->getRealPath());
            }
        }
        rmdir($dir);
    }
    // liveExecuteCommand is (no longer used by backup)
    private static function liveExecuteCommand($cmd) {
        while (@ ob_end_flush());
        $proc = popen("$cmd 2>&1", 'r');
        if ($proc === false) {
            echo "Error: Failed to execute command: $cmd\n";
            return;
        }
        $live_output = "";
        $complete_output = "";
        while (!feof($proc)) {
            $live_output = fread($proc, 4096);
            if ($live_output === false) {
                break;
            }
            $complete_output = $complete_output . $live_output;
            echo "$live_output";
            @ flush();
        }

        pclose($proc);
    }
}

// Check if the script is being run directly from the command line
if (php_sapi_name() == 'cli') {
    // Ensure vendor autoload is required relative to this script's directory
    require_once __DIR__ . '/vendor/autoload.php';
    \Disembark\Run::main($argv, $argc);
}