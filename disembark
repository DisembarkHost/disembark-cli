#!/usr/bin/env php
<?php
namespace Disembark;

class Run {

    const VERSION = '2.2.0';

    public static function main($argv, $argc) {
        if ($argc < 2) {
            self::showHelp();
            exit(0);
        }

        $command = $argv[1];
        switch ($command) {
            case 'connect':
                if ($argc != 4) {
                    echo "Error: Invalid arguments for connect\n";
                    exit(1);
                }
                $siteUrl = $argv[2];
                $token = $argv[3];
                self::connect($siteUrl, $token);
                break;

            case 'list':
                if ($argc != 2) {
                    echo "Error: Invalid arguments for list\n";
                    exit(1);
                }
                self::sites();
                break;
            case 'backup':
                if ($argc < 3) {
                    echo "Error: Invalid arguments for backup\nRequires: <site-url> [options]\n";
                    exit(1);
                }
                $siteUrl = $argv[2];
                $exclude_paths = [];
                $exclude_tables_str = '';
                $preview = false;
                $session_id = null;
                $i = 3;
                while ($i < $argc) {
                    if ($argv[$i] === '--preview') {
                        $preview = true;
                        $i++;
                        continue;
                    }
                    if (strpos($argv[$i], '--session-id=') === 0) {
                        $session_id = substr($argv[$i], strlen('--session-id='));
                        $i++;
                        continue;
                    }
                    if ($argv[$i] === '-x') {
                        if (isset($argv[$i + 1])) {
                            $exclude_paths[] = rtrim($argv[$i + 1], '/');
                            $i += 2;
                        } else {
                            echo "Error: Missing value for -x option.\n";
                            exit(1);
                        }
                    } elseif (strpos($argv[$i], '--exclude-tables=') === 0) {
                        $exclude_tables_str = substr($argv[$i], strlen('--exclude-tables='));
                        $i++;
                    } else {
                        echo "Error: Unknown argument '{$argv[$i]}'\n";
                        self::showHelp();
                        exit(1);
                    }
                }
                $exclude_tables = !empty($exclude_tables_str) ? explode(',', $exclude_tables_str) : [];
                self::backup($siteUrl, $exclude_paths, $exclude_tables, $preview, $session_id);
                break;
            case 'version':
                if ($argc != 2) {
                    echo "Error: Invalid arguments for version\n";
                    exit(1);
                }
                self::version();
                break;
            case 'upgrade':
                if ($argc != 2) {
                    echo "Error: Invalid arguments for upgrade\n";
                    exit(1);
                }
                self::upgrade();
                break;
            case 'sync':
                if ($argc < 3) {
                    echo "Error: Invalid arguments for sync\nRequires: <site-url> [<folder>] [--debug]\n";
                    exit(1);
                }
                $siteUrl = $argv[2];
                $folder = null;
                $debug = false;
                $session_id = null;

                $args = array_slice($argv, 3);
                foreach ($args as $arg) {
                    if ($arg === '--debug') {
                        $debug = true;
                    } elseif (strpos($arg, '--session-id=') === 0) {
                        $session_id = substr($arg, strlen('--session-id='));
                    } elseif ($folder === null && strpos($arg, '--') !== 0) {
                        $folder = $arg;
                    }
                }

                if ($folder === null) {
                    $folder = preg_replace('/^https?:\/\/(www\.)?/', '', rtrim($siteUrl, '/'));
                }

                // Resolve $folder to an absolute path to avoid phar ambiguity.
                // Check if $folder is already absolute (e.g., /var/www or C:\www)
                if (
                    substr($folder, 0, 1) !== DIRECTORY_SEPARATOR && 
                    !(strlen($folder) > 1 && substr($folder, 1, 1) === ':') 
                ) {
                    $folder = getcwd() . DIRECTORY_SEPARATOR . $folder;
                }

                self::sync($siteUrl, $folder, $debug, $session_id);
                break;
            default:
                echo "Error: Unknown command '$command'.\n\n";
                self::showHelp();
                exit(1);
        }
    }

    private static function connect($siteUrl, $token) {
        // Trim trailing slashes from the site URL
        $siteUrl = rtrim($siteUrl, '/');
        // Verify the site URL starts with http:// or https://
        if (!preg_match('/^https?:\/\//', $siteUrl)) {
            $siteUrl = "https://$siteUrl";
            echo "The site URL must start with http:// or https://. Attempting to use $siteUrl\n";
        }

        $homeDir = getenv('HOME');
        if (!$homeDir) {
            echo "Error: Unable to determine the home directory.\n";
            exit(1);
        }

        if (empty($siteUrl) || empty($token)) {
            echo "Error: Required arguments <site-url> and <token>.\n";
            exit(1);
        }
        try {
            // Test connection by fetching database info
            $response = \WpOrg\Requests\Requests::get("$siteUrl/wp-json/disembark/v1/database?token=$token", [], ['verify' => false, 'timeout' => 60]);
        } catch (\WpOrg\Requests\Exception $e) {
            // Handle the exception
            echo "Error: Request failed with error: {$e->getMessage()}\n";
            exit(1);
        }

        if ($response->status_code != 200) {
            echo "Error: Failed to connect to $siteUrl. Status code: {$response->status_code}. Please check your URL, token, and ensure the Disembark plugin is active.\n";
            exit(1);
        }

        $tables = json_decode($response->body);
        if (empty($tables)) {
            echo "Error: Connected to $siteUrl, but failed to retrieve database information. Please check plugin functionality.\n";
            exit(1);
        }

        $filePath = $homeDir . '/.disembark';
        $data = [];
        // Check if the file already exists and read its contents
        if (file_exists($filePath)) {
            $jsonContents = file_get_contents($filePath);
            $data = json_decode($jsonContents);
            // Ensure $data is always an array for consistent processing
            if (!is_array($data)) {
                // Try decoding as an object first for legacy compatibility
                if (is_object($data)) {
                    // Convert object to array of objects
                    $data = [$data];
                } else {
                    $data = []; // Initialize as empty array if decoding failed or was invalid
                }
            }
        }

        // Check if the siteUrl already exists and update it, otherwise add new
        $found = false;
        foreach ($data as $key => $entry) {
            // Ensure entry is an object before accessing properties
            if (is_object($entry) && !empty($entry->siteUrl) && $entry->siteUrl === $siteUrl) {
                $data[$key]->token = $token; // Update token directly on the object within the array
                $found = true;
                break;
            }
        }

        if (!$found) {
            // Add new entry as an object
            $data[] = (object) [
                'siteUrl' => $siteUrl,
                'token' => $token
            ];
        }

        $jsonData = json_encode($data, JSON_PRETTY_PRINT);
        if (file_put_contents($filePath, $jsonData) === false) {
            echo "Error: Unable to write to $filePath.\n";
            exit(1);
        }

        echo "Successfully connected to $siteUrl and saved credentials to $filePath\n";
    }

    private static function make_request($siteUrl, $token, $backup_token, $endpoint, $payload = [], $method = 'POST') {
        $headers = ['Content-Type' => 'application/json; charset=utf-8'];
        $data = array_merge(['token' => $token, 'backup_token' => $backup_token], $payload);
        $url = "$siteUrl/wp-json/disembark/v1" . $endpoint;
        $options = ['verify' => false, 'timeout' => 600]; // Standard timeout for most steps

        try {
            switch (strtoupper($method)) {
                case 'POST':
                    // Increase timeout specifically for zip operations which can take longer
                    if ($endpoint === '/zip-files' || $endpoint === '/zip-database') {
                        $options['timeout'] = 1800; // 30 minutes
                    } elseif (strpos($endpoint, '/export/database/') === 0 && isset($payload['parts'])) {
                        $options['timeout'] = 1200; // 20 minutes for large table parts
                    }
                    $response = \WpOrg\Requests\Requests::post($url, $headers, json_encode($data), $options);
                    break;
                case 'GET':
                default:
                    // Increase timeout for cleanup as well
                    if ($endpoint === '/cleanup') {
                        $options['timeout'] = 120;
                    }
                    // For GET, build query params correctly
                    $query_params = http_build_query($data);
                    $response = \WpOrg\Requests\Requests::get($url . '?' . $query_params, [], $options); // Pass empty headers array for GET
                    break;
            }

            if ($response->status_code !== 200) {
                $errorMessage = "Error: Request to {$endpoint} failed. HTTP status: {$response->status_code}.";
                $errorBody = json_decode($response->body);
                if (json_last_error() === JSON_ERROR_NONE && isset($errorBody->message)) {
                    $errorMessage .= " Message: " . $errorBody->message;
                } else {
                    $errorMessage .= " Response: " . substr($response->body, 0, 500);
                }
                echo $errorMessage . "\n";
                // Throw an exception instead of exiting directly to allow potential cleanup
                throw new \Exception("API request failed for {$endpoint}");
            }

            $decoded = json_decode($response->body);
            // Check if this endpoint is allowed to return a raw string (like a path or URL)
            $allowed_raw_endpoints = ['/cleanup', '/zip-database', '/zip-files'];
            $is_raw_endpoint = false;
            foreach ($allowed_raw_endpoints as $raw_ep) {
                if ($endpoint === $raw_ep) $is_raw_endpoint = true;
            }
            if (strpos($endpoint, '/export/database/') === 0) {
                $is_raw_endpoint = true;
            }

            if (json_last_error() !== JSON_ERROR_NONE) {
                // Not JSON.
                // Is it an endpoint that *should* return a raw string?
                if (!empty(trim($response->body)) && $is_raw_endpoint) {
                    return trim($response->body); // Return the raw body (e.g., URL)
                }
                // Not JSON and not an allowed raw endpoint, or it's empty
                if (!empty(trim($response->body))) {
                    echo "Error: Could not decode JSON response from {$endpoint}. Response: " . substr($response->body, 0, 500) . "\n";
                    throw new \Exception("Invalid JSON response for {$endpoint}");
                }
                // Allow empty responses for cleanup
                if ($endpoint === '/cleanup') {
                    return "Cleanup requested";
                }
            }

            // If it *is* valid JSON, but the API might have returned a JSON-encoded string (e.g. "path\/to\/file.sql")
            // json_decode will have correctly turned this into a PHP string.
            // If it was a JSON object/array, it will be a PHP object/array.
            return $decoded;
        } catch (\WpOrg\Requests\Exception $e) {
            echo "Error: Request failed for {$endpoint}: {$e->getMessage()}\n";
            // Re-throw or handle as needed
            throw $e; // Re-throw to allow potential cleanup in calling function
        }
    }

    /**
     * Runs the remote manifest generation process.
     * Can optionally request file checksums for sync operations.
     * @return array List of manifest chunk file objects.
     */
    private static function runManifestGeneration($siteUrl, $token, $backup_token, $exclude_paths, $include_checksums = false) {

        $files_manifests = [];
        try {
            echo "Running analysis (this may take a while)...\n";
            $exclude_files_string = implode("\n", $exclude_paths);

            $payload = [
                'exclude_files' => $exclude_files_string
            ];
            if ($include_checksums) {
                $payload['include_checksums'] = true;
            }

            // Step 1: Initiate
            self::make_request($siteUrl, $token, $backup_token, '/regenerate-manifest', ['step' => 'initiate'] + $payload, 'POST');
            echo "Initiated file scan.\n";

            // Step 2: Scan Loop
            $scan_complete = false;
            $last_scan_output = "";
            while (!$scan_complete) {
                $scan_response = self::make_request($siteUrl, $token, $backup_token, '/regenerate-manifest', ['step' => 'scan'] + $payload, 'POST');
                if (!is_object($scan_response) || !isset($scan_response->status)) {
                    throw new \Exception("Invalid response received during scan step.");
                }

                if ($scan_response->status === 'scan_complete') {
                    $scan_complete = true;
                    echo str_pad("", strlen($last_scan_output), " ") . "\r";
                    printf("Scanning complete. Analyzed %d directories.\n", $scan_response->total_dirs ?? 0);
                } else if (isset($scan_response->scanned_dirs) && isset($scan_response->total_dirs)) {
                    $last_scan_output = sprintf("Scanning... (%d / %d directories)", $scan_response->scanned_dirs, $scan_response->total_dirs);
                    echo $last_scan_output . "\r";
                } else {
                    echo "\nWarning: Scan step response might be incomplete.\n";
                }
                usleep(250000);
            }

            // Step 3: Chunkify
            echo "Chunkifying file list...\n";
            $chunk_response = self::make_request($siteUrl, $token, $backup_token, '/regenerate-manifest', ['step' => 'chunkify'] + $payload, 'POST');
            $total_chunks = $chunk_response->total_chunks ?? 0;
            if ($total_chunks === 0) {
                echo "No files found to analyze or an error occurred during chunkification.\n";
            } else {
                echo "File list divided into {$total_chunks} chunks.\n";
            }


            // Step 4: Process Chunks
            $last_chunk_output = "";
            for ($i = 1; $i <= $total_chunks; $i++) {
                $last_chunk_output = sprintf("Processing chunk %d of %d...", $i, $total_chunks);
                echo $last_chunk_output . "\r";
                self::make_request($siteUrl, $token, $backup_token, '/regenerate-manifest', ['step' => 'process_chunk', 'chunk' => $i] + $payload, 'POST');
                usleep(50000);
            }
            if ($total_chunks > 0) {
                echo str_pad("", strlen($last_chunk_output), " ") . "\r";
                echo "Chunk processing complete.\n";
            }


            // Step 5: Finalize
            $files_manifests = self::make_request($siteUrl, $token, $backup_token, '/regenerate-manifest', ['step' => 'finalize'] + $payload, 'POST');
            if (!is_array($files_manifests)) {
                echo "Warning: Final manifest data is not in the expected format. File stats may be inaccurate.\n";
                $files_manifests = [];
            }
            echo "Analysis complete.\n";
        } catch (\Exception $e) {
            echo "Error during file analysis: {$e->getMessage()}\n";
            self::cleanupTemporaryFiles($siteUrl, $token, $backup_token); // Attempt cleanup
            exit(1);
        }

        // Return the generated manifest
        return $files_manifests;
    }

    private static function displayBackupSummary($siteUrl, $token, $files_manifests, $exclude_tables) {
        // 2. Fetch database info
        $all_tables = [];
        try {
            $response_db = \WpOrg\Requests\Requests::get("$siteUrl/wp-json/disembark/v1/database?token=$token", [], ['verify' => false, 'timeout' => 600]);
            if ($response_db->status_code !== 200) {
                echo "Error: Failed to fetch database info. HTTP response code: {$response_db->status_code}\n";
                exit(1);
            }
            $all_tables = json_decode($response_db->body);
            if (json_last_error() !== JSON_ERROR_NONE || !is_array($all_tables)) {
                echo "Error: Invalid database info received.\n";
                $all_tables = [];
            }
        } catch (\WpOrg\Requests\Exception $e) {
            echo "Error: Failed to fetch database info: {$e->getMessage()}\n";
            exit(1);
        }

        // 3. Calculate file stats TO BE BACKED UP
        $remainingFiles = empty($files_manifests) ? 0 : array_sum(array_column($files_manifests, 'count'));
        $remainingSize = empty($files_manifests) ? 0 : array_sum(array_column($files_manifests, 'size'));
        // 4. Calculate database stats
        $totalTables = count($all_tables);
        $totalDbSize = empty($all_tables) ? 0 : array_sum(array_column($all_tables, 'size'));
        $excludedTables = 0;
        $excludedDbSize = 0;

        $included_table_list = [];
        foreach ($all_tables as $table) {
            $table_size = isset($table->size) && is_numeric($table->size) ? (float)$table->size : 0;
            $is_excluded = false;
            foreach ($exclude_tables as $pattern) {
                if (fnmatch($pattern, $table->table)) {
                    $is_excluded = true;
                    break;
                }
            }
            if ($is_excluded) {
                $excludedTables++;
                $excludedDbSize += $table_size;
            } else {
                $table->size = $table_size;
                $included_table_list[] = $table;
            }
        }
        $remainingTables = $totalTables - $excludedTables;
        $remainingDbSize = empty($included_table_list) ? 0 : array_sum(array_column($included_table_list, 'size'));


        // 5. Display results
        echo "\nBackup Preview: $siteUrl\n";
        echo "* Exclusions are applied server-side during analysis.\n";
        echo "* The summary below shows only files and tables scheduled for backup.\n\n";
        echo "File Backup Summary\n";
        printf("%-24s %12s %12s\n", "", "Count", "Size");
        printf("%-24s %12s %12s\n", str_repeat('-', 24), str_repeat('-', 12), str_repeat('-', 12));
        printf("%-24s %12s %12s\n", "Files to be Backed Up:", number_format($remainingFiles), self::humanFilesize($remainingSize));

        echo "\nDatabase Backup Summary\n";
        printf("%-24s %12s %12s\n", "", "Count", "Size");
        printf("%-24s %12s %12s\n", str_repeat('-', 24), str_repeat('-', 12), str_repeat('-', 12));
        printf("%-24s %12s %12s\n", "Total Tables:", number_format($totalTables), self::humanFilesize($totalDbSize));
        printf("%-24s %12s %12s\n", "Excluded Tables:", number_format($excludedTables), self::humanFilesize($excludedDbSize));
        printf("%-24s %12s %12s\n", "Tables to be Backed Up:", number_format($remainingTables), self::humanFilesize($remainingDbSize));
        echo "\n* This is an estimate. Actual backup size may vary.\n";
    }

    private static function runPreview($siteUrl, $token, $backup_token, $exclude_paths, $exclude_tables) {

        // 1. Run the manifest generation
        $files_manifests = self::runManifestGeneration($siteUrl, $token, $backup_token, $exclude_paths, false);
        // 2. Display the summary
        self::displayBackupSummary($siteUrl, $token, $files_manifests, $exclude_tables);
        // 3. Return the generated manifest
        return $files_manifests;
    }

    // Helper function specifically for cleanup after preview or backup failure
    private static function cleanupTemporaryFiles($siteUrl, $token, $backup_token) {
        echo "Cleaning up temporary files on server...\n";
        try {
            $payload = ['backup_token' => $backup_token];
            self::make_request($siteUrl, $token, $backup_token, '/cleanup', $payload, 'GET');
            echo "Cleanup request sent.\n";
        } catch (\Exception $e) {
            echo "Warning: Cleanup request failed: {$e->getMessage()}\n";
            // Don't exit here, cleanup failure is not critical for the overall process
        }
    }

    /**
     * Processes the database backup using hybrid batching.
     *
     * @param string $siteUrl
     * @param string $token
     * @param string $backup_token
     * @param array $tables_to_backup List of table objects to be backed up.
     * @param string $db_export_file The final, local SQL file path to append to.
     * @param string $local_db_parts_path A temporary directory to store downloaded SQL chunks.
     * @throws \Exception
     */
    private static function processDatabaseBackup($siteUrl, $token, $backup_token, $tables_to_backup, $db_export_file, $local_db_parts_path) {
        
        echo "Backing up database tables...\n";

        // --- Hybrid Batching Logic ---
        $large_tables = [];
        $small_tables = [];
        $max_size = 209715200; // 200 MB
        $max_rows = 1000000;   // 1 million rows

        foreach ($tables_to_backup as $table) {
            $table_size = isset($table->size) && is_numeric($table->size) ? (float)$table->size : 0;
            $row_count = isset($table->row_count) && is_numeric($table->row_count) ? (int)$table->row_count : 0;

            if (($table_size > $max_size || $row_count > $max_rows) && $row_count > 0) {
                $parts_by_size = ceil($table_size / $max_size);
                $parts_by_rows = ceil($row_count / $max_rows);
                $parts = max($parts_by_size, $parts_by_rows);
                
                $table->parts = $parts;
                $table->current = 0;
                $table->rows_per_part = ceil($row_count / $parts);
                $large_tables[] = $table;
            } else {
                $table->parts = 0;
                $small_tables[] = $table;
            }
        }

        $small_table_batches = [];
        $current_batch = [];
        $current_batch_size = 0;
        foreach ($small_tables as $table) {
            $table_size = isset($table->size) && is_numeric($table->size) ? (float)$table->size : 0;
            if ($current_batch_size + $table_size > $max_size && !empty($current_batch)) {
                $small_table_batches[] = $current_batch;
                $current_batch = [];
                $current_batch_size = 0;
            }
            $current_batch[] = $table;
            $current_batch_size += $table_size;
        }
        if (!empty($current_batch)) {
            $small_table_batches[] = $current_batch;
        }
        // --- End Hybrid Batching ---

        // Calculate total steps
        $total_db_steps = count($small_table_batches);
        foreach ($large_tables as $table) {
            $total_db_steps += ($table->parts > 0) ? $table->parts : 1;
        }
        $current_db_step = 0;

        // --- Loop 1: Process small table batches ---
        foreach ($small_table_batches as $batch) {
            $current_db_step++;
            $table_names = array_column($batch, 'table');
            $batch_size = array_sum(array_column($batch, 'size'));
            $progress_message = sprintf(" - Exporting batch %d/%d (%d tables, %s)", $current_db_step, $total_db_steps, count($batch), self::humanFilesize($batch_size));
            echo $progress_message . "...\r";

            $file_url = self::make_request($siteUrl, $token, $backup_token, "/export-database-batch", ['tables' => $table_names], 'POST');
            if (strpos($file_url, 'http') !== 0) {
                throw new \Exception("Export failed for batch, did not receive a valid URL. Got: $file_url");
            }
            $file_name = basename($file_url);
            $local_file_path = $local_db_parts_path . '/' . $file_name;

            $parsed_url = parse_url($file_url);
            $relative_path = ltrim($parsed_url['path'], '/');
            self::download_db_file($siteUrl, $token, $relative_path, $local_file_path);

            file_put_contents($db_export_file, file_get_contents($local_file_path), FILE_APPEND);
            unlink($local_file_path); // Delete local SQL part

            self::make_request($siteUrl, $token, $backup_token, '/cleanup-file', ['file_name' => $file_name], 'POST');
            echo $progress_message . " - Done.\n";
            usleep(50000);
        }

        // --- Loop 2: Process large tables ---
        foreach ($large_tables as $table) {
            if (!isset($table->table)) {
                echo "\nWarning: Skipping invalid table data entry in backup.\n";
                continue;
            }

            for ($part = 1; $part <= $table->parts; $part++) {
                $current_db_step++;
                $total_table_size = (float)$table->size;
                $current_part_size = $max_size;
                if ($part == $table->parts) {
                    $current_part_size = $total_table_size - ($max_size * ($table->parts - 1));
                }
                
                $description = sprintf("%s %d/%d", $table->table, $part, $table->parts);
                $size_string = self::humanFilesize($current_part_size);
                $progress_message = sprintf(" - Exporting batch %d/%d (%s, %s)", $current_db_step, $total_db_steps, $description, $size_string);
                echo $progress_message . "...\r";
                
                $part_data = ['parts' => $part, 'rows_per_part' => $table->rows_per_part];
                $file_url = self::make_request($siteUrl, $token, $backup_token, "/export/database/{$table->table}", $part_data, 'POST');
                if (strpos($file_url, 'http') !== 0) {
                    throw new \Exception("Export failed, did not receive a valid URL. Got: $file_url");
                }
                $file_name = basename($file_url);
                $local_file_path = $local_db_parts_path . '/' . $file_name;

                $parsed_url = parse_url($file_url);
                $relative_path = ltrim($parsed_url['path'], '/');
                self::download_db_file($siteUrl, $token, $relative_path, $local_file_path);

                file_put_contents($db_export_file, file_get_contents($local_file_path), FILE_APPEND);
                unlink($local_file_path); // Delete local SQL part

                self::make_request($siteUrl, $token, $backup_token, '/cleanup-file', ['file_name' => $file_name], 'POST');
                echo $progress_message . " - Done.\n";
                usleep(50000);
            }
        }
        echo "Database export and download complete.\n";
    }

    /**
     * Performs a local or remote sync.
     */
    private static function sync($siteUrl, $folder, $debug = false, $session_id = null) {
        // --- 1. Authentication ---
        $siteUrl = rtrim($siteUrl, '/');
        if (!preg_match('/^https?:\/\//', $siteUrl)) {
            $siteUrl = "https://$siteUrl";
        }
        $homeDir = getenv('HOME');
        if (!$homeDir) {
            echo "Error: Unable to determine the home directory.\n";
            exit(1);
        }
        $filePath = $homeDir . '/.disembark';
        $data = [];
        if (file_exists($filePath)) {
            $data = json_decode(file_get_contents($filePath));
            if (!is_array($data)) {
                if (is_object($data)) $data = [$data];
                else {
                    echo "Error: Invalid data in $filePath.\n";
                    exit(1);
                }
            }
        } else {
            echo "Error: No configuration file found at $filePath.\n";
            exit(1);
        }
        $token = null;
        foreach ($data as $entry) {
            if (is_object($entry) && isset($entry->siteUrl) && $entry->siteUrl === $siteUrl) {
                $token = $entry->token;
                break;
            }
        }
        if (empty($token)) {
            echo "Error: No token found for $siteUrl.\n";
            exit(1);
        }

        // --- 2. Setup ---
        $backup_token = "";
        if ($session_id) {
            $backup_token = $session_id;
            echo "Reusing backup session: $backup_token\n";
        } else {
            $backup_token = substr(bin2hex(random_bytes(20)), 0, -28);
        }
        $is_initial_sync = !is_dir($folder);
        if ($is_initial_sync) {
            echo "Performing initial sync to new folder: $folder\n";
            if (!mkdir($folder, 0755, true)) {
                echo "Error: Could not create folder at $folder.\n";
                exit(1);
            }
        } else {
            echo "Performing subsequent sync to existing folder: $folder\n";
        }

        $local_db_parts_path = $folder . '/.disembark-db-parts';
        $db_export_file = $folder . '/database.sql';
        try {
            // --- 3. Database Sync (Always run) ---
            echo "Starting database sync...\n";
            if (!is_dir($local_db_parts_path) && !mkdir($local_db_parts_path, 0755, true)) {
                throw new \Exception("Could not create temp DB directory.");
            }
            $sql_header = "/*!40101 SET NAMES utf8 */;\nSET sql_mode='NO_AUTO_VALUE_ON_ZERO';\n";
            if (file_put_contents($db_export_file, $sql_header) === false) {
                throw new \Exception("Could not write to local SQL file.");
            }

            // Fetch the full database list
            $response = \WpOrg\Requests\Requests::get("$siteUrl/wp-json/disembark/v1/database?token=$token", [], ['verify' => false, 'timeout' => 600]);
            if ($response->status_code !== 200 || empty($response->body)) throw new \Exception("Could not get list of database tables.");
            $database = json_decode($response->body);
            if (json_last_error() !== JSON_ERROR_NONE || !is_array($database)) throw new \Exception("Invalid database list received.");

            // Sync always backs up all tables, so we pass the full $database list
            self::processDatabaseBackup($siteUrl, $token, $backup_token, $database, $db_export_file, $local_db_parts_path);
            self::delete_directory($local_db_parts_path); // Clean up temp dir

            // --- 4. File Sync ---
            $files_manifest_chunks = [];
            if ($session_id) {
                echo "Fetching existing manifest for sync...\n";
                try {
                    $files_manifest_chunks = self::make_request($siteUrl, $token, $backup_token, '/manifest', [], 'GET');
                    if (!is_array($files_manifest_chunks)) {
                        throw new \Exception("Could not fetch or parse existing manifest. Is the backup ID valid?");
                    }
                    echo "Successfully fetched manifest with " . count($files_manifest_chunks) . " file chunks.\n";
                } catch (\Exception $e) {
                    echo "Error fetching manifest: {$e->getMessage()}\n";
                    if (!$session_id) {
                        self::cleanupTemporaryFiles($siteUrl, $token, $backup_token);
                    }
                    exit(1);
                }
            } else {
                // --- Run generation if no $session_id ---
                echo "Starting file sync analysis...\n";
                $exclude_paths = []; // Syncs don't support exclusions by default
                $files_manifest_chunks = self::runManifestGeneration($siteUrl, $token, $backup_token, $exclude_paths, !$is_initial_sync);
            }

            if ($is_initial_sync) {
                // --- 4a. Initial Sync: Download all zips and extract ---
                echo "Performing initial file download...\n";
                $steps = count($files_manifest_chunks);
                $current_step = 1;
                foreach ($files_manifest_chunks as $file_manifest) {
                    if (!is_object($file_manifest) || !isset($file_manifest->name) || !isset($file_manifest->url)) continue;
                    $size = self::humanFilesize($file_manifest->size);
                    $progress_message = sprintf(" - Downloading and extracting chunk %d/%d (%s)", $current_step, $steps, $size);
                    echo $progress_message . "...\r";
                    $file_url = self::make_request($siteUrl, $token, $backup_token, '/zip-files', ['file' => $file_manifest->name, 'exclude_files' => ''], 'POST');
                    if (strpos($file_url, 'http') !== 0) throw new \Exception("Zip failed for {$file_manifest->name}");

                    $file_name = basename($file_url);
                    $local_zip_chunk_path = $folder . '/' . $file_name; // Temp file in root

                    self::download_file_direct($file_url, $local_zip_chunk_path);
                    self::unzip_file($local_zip_chunk_path, $folder); // Unzip directly to target
                    unlink($local_zip_chunk_path); // Delete temp zip
                    self::make_request($siteUrl, $token, $backup_token, '/cleanup-file', ['file_name' => $file_name], 'POST');
                    echo $progress_message . " - Done.\n";
                    $current_step++;
                }
                echo "Initial file sync complete.\n";
            } else {
                // --- 4b. Subsequent Sync: Diff and download ---
                echo "Fetching remote file manifest...\n";
                $remote_files_map = [];
                $temp_manifest_dir = $folder . '/.disembark-manifests';
                if (!is_dir($temp_manifest_dir) && !mkdir($temp_manifest_dir, 0755, true)) throw new \Exception("Could not create temp manifest dir.");
                $all_remote_files = []; // Store all files here

                foreach ($files_manifest_chunks as $file_manifest) {
                    $chunk_url = $file_manifest->url;
                    $local_chunk_path = $temp_manifest_dir . '/' . $file_manifest->name;
                    self::download_file_direct($chunk_url, $local_chunk_path);
                    $files = json_decode(file_get_contents($local_chunk_path));
                    if (is_array($files)) {
                        foreach ($files as $file) {
                            if (isset($file->name)) {
                                $remote_files_map[$file->name] = $file;
                                $all_remote_files[] = $file; // Add to full list
                            }
                        }
                    }
                    unlink($local_chunk_path);
                }
                self::delete_directory($temp_manifest_dir);
                if ($debug) {
                    $remote_manifest_path = $folder .
                        '/.disembark-remote-manifest.json';
                    file_put_contents($remote_manifest_path, json_encode($all_remote_files, JSON_PRETTY_PRINT));
                    echo "Debug: Saved remote manifest to $remote_manifest_path\n";
                }

                echo "Generating local file manifest...\n";
                $local_files_map = self::generate_local_manifest($folder);

                if ($debug) {
                    $local_manifest_path = $folder . '/.disembark-local-manifest.json';
                    // We need the list, not the map, for a comparable JSON
                    file_put_contents($local_manifest_path, json_encode(array_values($local_files_map), JSON_PRETTY_PRINT));
                    echo "Debug: Saved local manifest to $local_manifest_path\n";
                }

                echo "Comparing manifests and syncing changes...\n";
                // 1. Find files to download and files to delete
                $files_to_download = [];
                $files_to_delete = [];

                foreach ($remote_files_map as $path => $remote_file) {
                    $local_file = $local_files_map[$path] ?? null;
                    if (!$local_file || !isset($remote_file->checksum) || $local_file->checksum !== $remote_file->checksum) {
                        $files_to_download[] = $remote_file; // Add the file object
                    }
                }

                foreach ($local_files_map as $path => $local_file) {
                    if (!isset($remote_files_map[$path])) {
                        $files_to_delete[] = $path;
                    }
                }

                // 2. Download a zip of new/changed files
                if (!empty($files_to_download)) {
                    $total_files_to_download = count($files_to_download);
                    echo " - Syncing $total_files_to_download new/changed file(s) in chunks...\n";

                    $chunk_size = 2500;
                    // Process 5000 files per zip
                    $file_chunks = array_chunk($files_to_download, $chunk_size);
                    $total_chunks = count($file_chunks);

                    foreach ($file_chunks as $index => $chunk) {
                        $chunk_num = $index + 1;
                        $chunk_file_count = count($chunk);
                        $progress_message = sprintf(" - Processing sync chunk %d of %d (%d files)", $chunk_num, $total_chunks, $chunk_file_count);
                        echo $progress_message . "...\r";

                        $attempts = 0;
                        $max_attempts = 3;
                        $success = false;
                        while ($attempts < $max_attempts && !$success) {
                            $attempts++;
                            $file_url = null;
                            $file_name = null;
                            $local_zip_chunk_path = null;

                            try {
                                // Call the server endpoint for the current chunk
                                $file_url = self::make_request($siteUrl, $token, $backup_token, '/zip-sync-files', ['files' => $chunk], 'POST');
                                if (strpos($file_url, 'http') !== 0) {
                                    // This is a server-side error, not a 503. Throw to trigger retry.
                                    throw new \Exception("Sync zip for chunk $chunk_num failed. Did not receive a valid URL. Got: $file_url");
                                }

                                $file_name = basename($file_url);
                                $local_zip_chunk_path = $folder . '/' . $file_name; // Temp file in root

                                self::download_file_direct($file_url, $local_zip_chunk_path);
                                self::unzip_file($local_zip_chunk_path, $folder); // Unzip directly to target
                                unlink($local_zip_chunk_path);
                                // Delete temp zip
                                
                                // Clean up remote zip chunk
                            
                                self::make_request($siteUrl, $token, $backup_token, '/cleanup-file', ['file_name' => $file_name], 'POST');
                                echo $progress_message . " - Done.        \n";
                                $success = true;
                                // Mark as successful to exit the while loop

                            } catch (\Exception $e) {
                                echo "\nWarning: Failed to process chunk $chunk_num (Attempt $attempts/$max_attempts): {$e->getMessage()}\n";
                                if (file_exists($local_zip_chunk_path)) unlink($local_zip_chunk_path);
                                // Also try to clean up remote file if it exists
                                if ($file_name) {
                                    self::make_request($siteUrl, $token, $backup_token, '/cleanup-file', ['file_name' => $file_name], 'POST');
                                }

                                if ($attempts < $max_attempts) {
                                    echo "Retrying in 5 seconds...\n";
                                    sleep(5);
                                } else {
                                    echo "Skipping this chunk after $max_attempts failed attempts. You may need to run sync again.\n";
                                }
                            }
                        } // end while $attempts
                    }
                    echo " - All sync chunks processed.\n";

                } else {
                    echo " - No new or changed files to download.\n";
                }

                // 3. Check for deleted files
                if (!empty($files_to_delete)) {
                    foreach ($files_to_delete as $path) {
                        echo " - Removing: $path\n";
                        $file_to_delete = $folder . DIRECTORY_SEPARATOR . $path;
                        if (file_exists($file_to_delete)) {
                            unlink($file_to_delete);
                        }
                    }
                } else {
                    echo " - No files to remove.\n";
                }

                echo "Cleaning up empty directories...\n";
                self::delete_empty_dirs($folder);
                echo "File sync complete.\n";
            }
        } catch (\Exception $e) {
            echo "\nSync failed: {$e->getMessage()}\n";
            if (!$session_id) {
                self::cleanupTemporaryFiles($siteUrl, $token, $backup_token);
            }
            exit(1);
        }

        // --- 5. Final Cleanup ---
        if (!$session_id) {
            self::cleanupTemporaryFiles($siteUrl, $token, $backup_token);
        } else {
            echo "\nSkipping remote cleanup to preserve UI session files.\n";
        }
        echo "\nSync complete: $folder is up to date.\n";
    }

    private static function backup($siteUrl, $exclude_paths = [], $exclude_tables = [], $preview = false, $session_id = null) {

        // Trim trailing slashes from the site URL
        $siteUrl = rtrim($siteUrl, '/');
        // Verify the site URL starts with http:// or https://
        if (!preg_match('/^https?:\/\//', $siteUrl)) {
            $siteUrl = "https://$siteUrl";
            echo "The site URL must start with http:// or https://. Attempting to use $siteUrl\n";
        }

        $homeDir = getenv('HOME');
        if (!$homeDir) {
            echo "Error: Unable to determine the home directory.\n";
            exit(1);
        }

        $filePath = $homeDir . '/.disembark';
        $data = [];
        // Check if the file already exists and read its contents
        if (file_exists($filePath)) {
            $jsonContents = file_get_contents($filePath);
            $data = json_decode($jsonContents);
            if (!is_array($data)) {
                if (is_object($data)) {
                    $data = [$data];
                } else {
                    echo "Error: Invalid data in $filePath.\n";
                    exit(1);
                }
            }
        } else {
            echo "Error: No configuration file found at $filePath.\nPlease run 'disembark connect <site-url> <token>' first.\n";
            exit(1);
        }

        // Find the token for the given siteUrl
        $token = null;
        foreach ($data as $entry) {
            if (is_object($entry) && isset($entry->siteUrl) && $entry->siteUrl === $siteUrl) {
                $token = $entry->token;
                break;
            }
        }

        if (empty($token)) {
            echo "Error: No token found for $siteUrl.\nRun 'disembark connect $siteUrl <token>' to configure.\n";
            exit(1);
        }

        $files = [];
        if ($session_id) {
            $backup_token = $session_id;
            echo "Reusing backup session: $backup_token\n";

            try {
                echo "Fetching existing manifest...\n";
                // Use the new /manifest GET endpoint
                $files = self::make_request($siteUrl, $token, $backup_token, '/manifest', [], 'GET');
                if (!is_array($files)) {
                    throw new \Exception("Could not fetch or parse existing manifest. Is the backup ID valid or is the manifest still generating?");
                }
                echo "Successfully fetched manifest with " . count($files) . " file chunks.\n";

                // Now display the summary based on the fetched manifest.
                // We pass an empty $exclude_tables array because the manifest is pre-generated.
                self::displayBackupSummary($siteUrl, $token, $files, []);
                echo "* Database exclusion summary reflects the pre-generated manifest; local --exclude-tables flag is ignored.\n";
            } catch (\Exception $e) {
                echo "Error fetching manifest: {$e->getMessage()}\n";
                // Do NOT clean up, it's not our session
                exit(1);
            }

            // If the preview flag is set, exit here.
            if ($preview) {
                echo "Preview complete. No cleanup performed as this is a reused session.\n";
                exit(0);
            }
        } else {
            // Generate unique token for this backup session
            $backup_token = substr(bin2hex(random_bytes(20)), 0, -28);
            // Run preview, which now also generates the manifest for the actual backup
            $files = self::runPreview($siteUrl, $token, $backup_token, $exclude_paths, $exclude_tables);
            // If the preview flag is set, clean up manifest files and exit.
            if ($preview) {
                self::cleanupTemporaryFiles($siteUrl, $token, $backup_token);
                exit(0);
            }
        }

        if (!empty($exclude_paths)) {
            echo "Excluding the following paths during backup:\n";
            foreach ($exclude_paths as $path) {
                echo " - $path\n";
            }
        }
        if (!empty($exclude_tables)) {
            echo "Excluding database tables matching:\n";
            foreach ($exclude_tables as $pattern) {
                echo " - $pattern\n";
            }
        }

        echo "Starting backup for $siteUrl using backup token $backup_token\n";
        // --- Setup Local Backup Environment ---
        // Create the directory name
        $temp_directory_name = "snapshot-" . time();
        // Use getcwd() to create a full, absolute path
        $temp_directory = getcwd() . DIRECTORY_SEPARATOR . $temp_directory_name;

        $local_db_path = $temp_directory . '/database';
        $local_public_path = $temp_directory . '/public';
        $domain = preg_replace('/^https?:\/\/(www\.)?/', '', $siteUrl);
        $domain = preg_replace('/\//', '_', $domain);
        $db_export_file = $local_public_path . '/database-' . $temp_directory_name . '.sql';
        $final_zip_name = "{$temp_directory_name}-{$domain}.zip";
        try {
            if (!mkdir($temp_directory, 0755, true)) throw new \Exception("Could not create temp directory $temp_directory.");
            if (!mkdir($local_db_path, 0755, true)) throw new \Exception("Could not create temp directory $local_db_path.");
            if (!mkdir($local_public_path, 0755, true)) throw new \Exception("Could not create temp directory $local_public_path.");
            // Write SQL headers
            $sql_header = "/*!40101 SET NAMES utf8 */;\nSET sql_mode='NO_AUTO_VALUE_ON_ZERO';\n";
            if (file_put_contents($db_export_file, $sql_header) === false) {
                throw new \Exception("Could not write to local SQL file $db_export_file.");
            }
            echo "Created local temporary directory at $temp_directory\n";
            // --- END Local Setup ---

            // --- Database Backup ---
            $database = [];
            try {
                // Fetch full table list
                $response = \WpOrg\Requests\Requests::get("$siteUrl/wp-json/disembark/v1/database?token=$token", [], ['verify' => false, 'timeout' => 600]);
                if ($response->status_code !== 200 || empty($response->body)) {
                    throw new \Exception("Could not get list of database tables. Status: " . $response->status_code);
                }
                $all_tables = json_decode($response->body);
                if (json_last_error() !== JSON_ERROR_NONE || !is_array($all_tables)) {
                    throw new \Exception("Invalid database list received during backup.");
                }

                // Filter tables based on exclusions
                if (!empty($exclude_tables)) {
                    foreach ($all_tables as $table) {
                        $is_excluded = false;
                        foreach ($exclude_tables as $pattern) {
                            if (fnmatch($pattern, $table->table)) {
                                $is_excluded = true;
                                break;
                            }
                        }
                        if (!$is_excluded) {
                            $database[] = $table; // Add non-excluded tables
                        }
                    }
                } else {
                    $database = $all_tables; // No exclusions, use all tables
                }
            } catch (\Exception $e) {
                echo "Error during database preparation: {$e->getMessage()}\n";
                throw $e; 
            }

            if (!empty($database)) {
                // Call the new helper function with the *filtered* list
                self::processDatabaseBackup($siteUrl, $token, $backup_token, $database, $db_export_file, $local_db_path);
            } else {
                echo "No database tables to back up (all were excluded or list is empty).\n";
            }

            rmdir($local_db_path); // Remove empty database temp dir

            // --- File Zipping ---
            if (!empty($files)) {
                $steps = count($files);
                $current_step = 1;
                $total_file_count = array_sum(array_column($files, 'count'));
                $total_file_size = self::humanFilesize(array_sum(array_column($files, 'size')));
                echo "Preparing to backup " . number_format($total_file_count) . " files totaling " . $total_file_size . "\n";
                $exclude_files_string = implode("\n", $exclude_paths);
                $zip_payload_base = [
                    "token" => $token,
                    "backup_token" => $backup_token,
                    "exclude_files" => $exclude_files_string,
                ];
                foreach ($files as $file_manifest) {
                    // Check for URL from manifest
                    if (!is_object($file_manifest) || !isset($file_manifest->name) || !isset($file_manifest->url)) {
                        echo "Warning: Skipping invalid manifest chunk data in zipping loop.\n";
                        $current_step++;
                        continue;
                    }

                    $size = self::humanFilesize($file_manifest->size);
                    $progress_message = sprintf(" - Zipping and downloading chunk %d/%d: %s files totaling %s", $current_step, $steps, number_format($file_manifest->count), $size);
                    echo $progress_message . "...\r";

                    $zip_payload = $zip_payload_base;
                    $zip_payload['file'] = $file_manifest->name;

                    // 1. Zip (now returns a full URL)
                    $file_url = self::make_request($siteUrl, $token, $backup_token, '/zip-files', $zip_payload, 'POST');
                    if (strpos($file_url, 'http') !== 0) {
                        throw new \Exception("Zip failed, did not receive a valid URL. Got: $file_url");
                    }
                    $file_name = basename($file_url);
                    $local_file_path = $temp_directory . '/' . $file_name;

                    // 2. Download (use new direct download function)
                    self::download_file_direct($file_url, $local_file_path);
                    // 3. Unzip locally
                    self::unzip_file($local_file_path, $local_public_path);
                    unlink($local_file_path); // Delete local zip chunk

                    // 4. Clean up remote zip chunk
                    self::make_request($siteUrl, $token, $backup_token, '/cleanup-file', ['file_name' => $file_name], 'POST');
                    echo $progress_message . " - Done.\n";
                    $current_step++;
                    usleep(100000);
                }
                echo "File zipping and download complete.\n";
            } else {
                echo "Skipping file backup as no files were included in the manifest.\n";
            }
            // --- End File Zipping ---

            // --- Final Local Zipping ---
            echo "Generating final local zip file: $final_zip_name...\n";
            self::zip_directory($local_public_path, $final_zip_name);
            echo "Successfully created $final_zip_name\n";
        } catch (\Exception $e) {
            // Catch any exception thrown during the backup process
            echo "\nBackup failed: {$e->getMessage()}\n";
            echo "Partial files may be left in {$temp_directory}\n";
            // Attempt remote cleanup even if backup failed, but only if it's not a reused session
            if (!$session_id) {
                self::cleanupTemporaryFiles($siteUrl, $token, $backup_token);
            }
            exit(1); // Exit with error status
        }

        // --- Final Cleanup ---
        try {
            echo "Cleaning up local temporary files...\n";
            self::delete_directory($temp_directory);
        } catch (\Exception $e) {
            echo "\nWarning: Failed to clean up local directory {$temp_directory}: {$e->getMessage()}\n";
        }

        // Final remote cleanup, only if it's not a reused session
        if (!$session_id) {
            self::cleanupTemporaryFiles($siteUrl, $token, $backup_token);
        } else {
            echo "\nSkipping remote cleanup to preserve UI session files.\n";
        }
        echo "\nBackup complete: $final_zip_name is ready.\n";
    }

    private static function sites() {
        $homeDir = getenv('HOME');
        if (!$homeDir) {
            echo "Error: Unable to determine the home directory.\n";
            exit(1);
        }

        $filePath = $homeDir . '/.disembark';
        $data = [];
        if (file_exists($filePath)) {
            $jsonContents = file_get_contents($filePath);
            $data = json_decode($jsonContents);
            if (!is_array($data)) {
                if (is_object($data)) {
                    $data = [$data];
                } else {
                    echo "Error: Invalid data in $filePath.\n";
                    exit(1);
                }
            }
        } else {
            echo "No configuration file found at $filePath. No sites connected.\n";
            exit(0);
        }

        if (empty($data)) {
            echo "No sites connected.\n";
        } else {
            echo "Connected sites:\n";
            foreach ($data as $entry) {
                if (is_object($entry) && isset($entry->siteUrl)) {
                    echo "- {$entry->siteUrl}\n";
                } else {
                    echo "- (Invalid entry in config file)\n";
                }
            }
        }
    }

    private static function version() {
        $version = self::VERSION;
        echo "Disembark CLI v{$version}\n";
    }

    private static function upgrade() {
        echo "Checking for updates...\n";
        $current_version = self::VERSION;

        $latest_version_cmd = "curl -sL -o /dev/null -w '%{url_effective}' https://github.com/DisembarkHost/disembark-cli/releases/latest | sed 's#.*/v##'";
        $latest_version = trim(shell_exec($latest_version_cmd));
        if (empty($latest_version) || !preg_match('/^\d+\.\d+\.\d+/', $latest_version)) {
            echo "Error: Could not fetch the latest version information or invalid version format received ('{$latest_version}').\n";
            exit(1);
        }

        if (version_compare($latest_version, $current_version, '>')) {
            echo "New version {$latest_version} available. Upgrading from {$current_version}...\n";
            $pharPath = \Phar::running(false);
            if (empty($pharPath)) {
                $scriptPath = realpath($_SERVER['argv'][0]);
                if ($scriptPath && is_file($scriptPath)) {
                    $pharPath = $scriptPath;
                    echo "Info: Determined script path as {$pharPath}.\n";
                } else {
                    echo "Error: Could not determine the path of the running script. Upgrade failed.\n";
                    echo "Please download the latest version manually from:\n";
                    echo "https://github.com/DisembarkHost/disembark-cli/releases/latest/download/disembark.phar\n";
                    exit(1);
                }
            }

            $downloadUrl = 'https://github.com/DisembarkHost/disembark-cli/releases/latest/download/disembark.phar';
            $tmpFile = tempnam(sys_get_temp_dir(), 'disembark-upgrade-');
            if ($tmpFile === false) {
                echo "Error: Could not create a temporary file. Upgrade failed.\n";
                exit(1);
            }

            echo "Downloading new version from {$downloadUrl}...\n";
            $download_cmd = sprintf("curl -sL '%s' -o '%s'", $downloadUrl, $tmpFile);
            shell_exec($download_cmd);
            if (!file_exists($tmpFile) || filesize($tmpFile) === 0) {
                echo "Error: Failed to download the new version. File is empty or does not exist at {$tmpFile}. Upgrade failed.\n";
                if (file_exists($tmpFile)) unlink($tmpFile);
                exit(1);
            }

            chmod($tmpFile, 0755);
            $move_cmd = sprintf("mv '%s' '%s'", $tmpFile, $pharPath);
            exec($move_cmd, $output, $return_var);
            if ($return_var !== 0) {
                echo "Error: Failed to replace the current script at {$pharPath}.\n";
                echo "You might need to run the command with sufficient permissions (e.g., using sudo):\n";
                echo "sudo disembark upgrade\n";
                if (file_exists($tmpFile)) {
                    unlink($tmpFile);
                }
                exit(1);
            }


            echo "Upgrade complete. You are now on version {$latest_version}.\n";
        } else {
            echo "You are already using the latest version ({$current_version}).\n";
        }
    }

    private static function showHelp() {
        echo "Disembark CLI\n";
        echo "\n";
        echo "Usage:\n";
        echo "  disembark backup <site-url> [options]\n";
        echo "  disembark sync <site-url> [<folder>] [options]\n";
        echo "  disembark <command>\n";
        echo "\n";
        echo "Primary Commands:\n";
        echo "\n";
        echo "  disembark backup <site-url> [options]\n";
        echo "    Initiate a backup for a connected site.\n";
        echo "\n";
        echo "    Options for backup:\n";
        echo "      --preview                          Show a summary of files and DB tables to be backed up without running the backup.\n";
        echo "      -x <path>                          Exclude a file or directory path (e.g., wp-content/cache). Can be specified multiple times.\n";
        echo "      --exclude-tables=<tables>          Exclude specific database tables (comma-separated, no spaces). Wildcards (*) are supported.\n";
        echo "      --session-id=<id>                  Reuse a specific backup session ID (backup token) generated by the plugin UI.\n";
        echo "\n";
        echo "  disembark sync <site-url> [<folder>] [options]\n";
        echo "    Create or update a local mirror of the site.\n";
        echo "\n";
        echo "    Options for sync:\n";
        echo "      --debug                            Save local and remote manifest files for debugging.\n";
        echo "      --session-id=<id>                  Reuse a backup session ID from the UI.\n";
        echo "\n";
        echo "Other Commands:\n";
        echo "  disembark connect <site-url> <token>   Connect to a site and save its token.\n";
        echo "  disembark list                         List all sites currently connected.\n";
        echo "  disembark upgrade                      Upgrade the Disembark CLI tool to the latest version.\n";
        echo "  disembark version                      Show the current version of the Disembark CLI tool.\n";
        echo "\n";
        echo "Example:\n";
        echo "  disembark backup https://example.com --preview -x wp-content/uploads/large-dir --exclude-tables=wp_options,wp_logs\n";
        echo "  disembark backup https://example.com --session-id=a1b2c3d4e5f6\n";
        echo "  disembark sync https://example.com --session-id=a1b2c3d4e5f6\n";
    }

    /**
     * Convert bytes to human-readable format.
     */
    private static function humanFilesize($bytes, $decimals = 2) {
        if ($bytes === null) return '0 B';
        if (!is_numeric($bytes)) return 'N/A';

        $bytesNum = (float) $bytes;

        if ($bytesNum == 0) return '0 B';

        $factor = floor(log($bytesNum, 1024));
        $sz = 'BKMGTP';
        $max_factor = strlen($sz) - 1;

        $factor = max(0, min((int)$factor, $max_factor));

        $size_str = sprintf("%.{$decimals}f", $bytesNum / pow(1024, $factor));
        $unit = $sz[$factor];
        $suffix = ($factor > 0) ? 'B' : '';

        return $size_str . ' ' . $unit . $suffix;
    }

    /**
     * Downloads a file directly from a URL using WpOrg\Requests.
     */
    private static function download_file_direct($url, $destination) {
        $attempts = 0;
        $max_attempts = 3;
        $last_error = "";

        while ($attempts < $max_attempts) {
            $attempts++;
            try {
                // Fetch response into memory, DO NOT stream to file
                $options = [
                    'verify' => false,
                    'timeout' => 1800,
                    'connect_timeout' => 30,
                ];
                $response = \WpOrg\Requests\Requests::get($url, [], $options);

                if (!$response->success) {
                    // Add response body to the error for debugging
                    throw new \Exception("Request failed with status code: {$response->status_code}. Body: " . substr($response->body, 0, 200));
                }

                // Manually write the response body to the file
                if (file_put_contents($destination, $response->body) === false) {
                    throw new \Exception("Failed to write downloaded content to $destination.");
                }

                return; // Success

            } catch (\Exception $e) {
                echo "\nWarning: Failed to download $url (Attempt $attempts/$max_attempts): {$e->getMessage()}\n";
                $last_error = $e->getMessage();
                if (file_exists($destination)) unlink($destination);
                if ($attempts < $max_attempts) {
                    echo "Retrying in 2 seconds...\n";
                    sleep(2);
                }
            }
        }

        // If loop finishes, it failed
        throw new \Exception("Failed to download $url after $max_attempts attempts. Last error: $last_error");
    }

    /**
     * Downloads a file from the /stream-file endpoint using WpOrg\Requests.
     */
    private static function download_file_via_stream($siteUrl, $token, $relative_path, $destination) {
        $attempts = 0;
        $max_attempts = 3;
        $last_error = "";

        while ($attempts < $max_attempts) {
            $attempts++;
            try {
                $endpoint_url = $siteUrl . '/wp-json/disembark/v1/stream-file';
                $payload = json_encode(['token' => $token, 'file' => $relative_path]);
                $headers = ['Content-Type' => 'application/json'];
                // Fetch response into memory, DO NOT stream to file
                $options = [
                    'verify' => false,
                    'timeout' => 1800,
                    'connect_timeout' => 30,
                ];
                $response = \WpOrg\Requests\Requests::post($endpoint_url, $headers, $payload, $options);
                if (!$response->success) {
                    // Add response body to the error for debugging
                    if ($response->status_code == 404 || $response->status_code == 403) {
                        throw new \Exception("Stream API failed: HTTP {$response->status_code}. Body: " . substr($response->body, 0, 200));
                    }
                    throw new \Exception("Stream API request failed with status code: {$response->status_code}. Body: " . substr($response->body, 0, 200));
                }

                // Manually write the response body to the file
                if (file_put_contents($destination, $response->body) === false) {
                    throw new \Exception("Failed to write downloaded stream content to $destination.");
                }

                return;
                // Success

            } catch (\Exception $e) {
                echo "\nWarning: Failed to stream $relative_path (Attempt $attempts/$max_attempts): {$e->getMessage()}\n";
                $last_error = $e->getMessage();
                if (file_exists($destination)) unlink($destination);
                if ($attempts < $max_attempts) {
                    echo "Retrying in 2 seconds...\n";
                    sleep(2);
                }
            }
        }

        // If loop finishes, streaming failed.
        throw new \Exception("Stream failed after $max_attempts attempts. Last error: $last_error");
    }

    /**
     * Downloads a database export file, trying direct download first and falling back to stream.
     */
    private static function download_db_file($siteUrl, $token, $relative_path, $destination) {
        // --- 1. Construct Direct URL ---
        // The relative path is already the full path from the WP root, e.g., wp-content/uploads/disembark/token/file.sql.txt
        // We need to URL-encode the components
        $path_parts = explode('/', $relative_path);
        $encoded_parts = array_map('rawurlencode', $path_parts);
        $encoded_relative_path = implode('/', $encoded_parts);
        $direct_url = $siteUrl . '/' . $encoded_relative_path;

        // --- 2. Try Direct Download First ---
        try {
            self::download_file_direct($direct_url, $destination);
            // If it succeeds, just return.
            return;
        } catch (\Exception $e) {
            echo "\nWarning: Direct download failed for '$relative_path': {$e->getMessage()}\n";
            echo "Attempting to download via stream API as fallback...\n";
        }

        // --- 3. Fallback to Stream API ---
        try {
            self::download_file_via_stream($siteUrl, $token, $relative_path, $destination);
            echo "Stream API download successful for: $relative_path\n";
        } catch (\Exception $e) {
            // Both methods failed. This is a fatal error for this file.
            echo "\nStream API fallback also failed: {$e->getMessage()}\n";
            throw new \Exception("Failed to download '$relative_path' using both direct and stream methods.");
        }
    }

    /**
     * Generates a local manifest of files with checksums.
     */
    private static function generate_local_manifest($dir) {
        $files_map = [];
        $real_root = realpath($dir);
        if ($real_root === false) return [];

        $iterator = new \RecursiveIteratorIterator(
            new \RecursiveDirectoryIterator($real_root, \RecursiveDirectoryIterator::SKIP_DOTS),
            \RecursiveIteratorIterator::SELF_FIRST
        );
        foreach ($iterator as $file) {
            if ($file->isDir()) continue;
            $path = $file->getRealPath();
            $relative_path = ltrim(substr($path, strlen($real_root)), DIRECTORY_SEPARATOR);

            // Skip sync-specific files
            if ($relative_path === 'database.sql' ||
                $relative_path === 'db_export.sql' || // Skip this file if it came from remote
                strpos($relative_path, '.disembark-db-parts') === 0 ||
                strpos($relative_path, '.disembark-manifests') === 0) {
                continue;
            }

            $files_map[$relative_path] = (object) [
                'name' => $relative_path,
                'size' => $file->getSize(),
                'checksum' => md5_file($path)
            ];
        }
        return $files_map;
    }

    /**
     * Recursively deletes empty directories.
     */
    private static function delete_empty_dirs($dir) {
        if (!is_dir($dir)) return;
        $iterator = new \RecursiveIteratorIterator(new \RecursiveDirectoryIterator($dir, \RecursiveDirectoryIterator::SKIP_DOTS), \RecursiveIteratorIterator::CHILD_FIRST);
        foreach ($iterator as $file) {
            if ($file->isDir() && !(new \FilesystemIterator($file->getPathname()))->valid()) {
                rmdir($file->getPathname());
            }
        }
    }

    /**
     * Unzips a file to a destination.
     */
    private static function unzip_file($file, $destination) {
        if (!class_exists('ZipArchive')) {
            echo "\nError: ZipArchive PHP extension is required to unpack files locally. Backup failed.\n";
            throw new \Exception('ZipArchive not found.');
        }
        $zip = new \ZipArchive;
        if ($zip->open($file) === TRUE) {
            if ($zip->extractTo($destination) === FALSE) {
                $zip->close();
                throw new \Exception("Failed to extract $file to $destination.");
            }
            $zip->close();
        } else {
            echo "\nError: Failed to open local zip archive $file. Backup failed.\n";
            throw new \Exception("Failed to open $file.");
        }
    }

    /**
     * Zips a directory into a single archive.
     */
    private static function zip_directory($source, $destination) {
        if (!class_exists('ZipArchive')) {
            throw new \Exception('ZipArchive PHP extension is required to create the final zip.');
        }
        $zip = new \ZipArchive();
        if (!$zip->open($destination, \ZipArchive::CREATE | \ZipArchive::OVERWRITE)) {
            throw new \Exception("Failed to create zip archive at $destination.");
        }

        $source = realpath($source);
        if ($source === false) {
            throw new \Exception("Source directory $source does not exist.");
        }

        $files = new \RecursiveIteratorIterator(
            new \RecursiveDirectoryIterator($source, \RecursiveDirectoryIterator::SKIP_DOTS),
            \RecursiveIteratorIterator::SELF_FIRST
        );
        // Add the root 'public' directory itself
        $zip->addEmptyDir('public');
        foreach ($files as $file) {
            $file = realpath($file);
            // Get relative path for root of zip
            $relativePath = 'public' . DIRECTORY_SEPARATOR . substr($file, strlen($source) + 1);

            if (empty($relativePath)) continue; // Skip the root folder itself

            if (is_dir($file)) {
                $zip->addEmptyDir($relativePath);
            } else if (is_file($file)) {
                $zip->addFile($file, $relativePath);
            }
        }
        $zip->close();
    }

    /**
     * Recursively deletes a directory.
     */
    private static function delete_directory($dir) {
        if (!is_dir($dir)) {
            return;
        }
        $it = new \RecursiveDirectoryIterator($dir, \RecursiveDirectoryIterator::SKIP_DOTS);
        $files = new \RecursiveIteratorIterator($it, \RecursiveIteratorIterator::CHILD_FIRST);
        foreach ($files as $file) {
            if ($file->isDir()) {
                rmdir($file->getRealPath());
            } else {
                unlink($file->getRealPath());
            }
        }
        rmdir($dir);
    }
    // liveExecuteCommand is (no longer used by backup)
    private static function liveExecuteCommand($cmd) {
        while (@ ob_end_flush());
        $proc = popen("$cmd 2>&1", 'r');
        if ($proc === false) {
            echo "Error: Failed to execute command: $cmd\n";
            return;
        }
        $live_output = "";
        $complete_output = "";
        while (!feof($proc)) {
            $live_output = fread($proc, 4096);
            if ($live_output === false) {
                break;
            }
            $complete_output = $complete_output . $live_output;
            echo "$live_output";
            @ flush();
        }

        pclose($proc);
    }
}

// Check if the script is being run directly from the command line
if (php_sapi_name() == 'cli') {
    // Ensure vendor autoload is required relative to this script's directory
    require_once __DIR__ . '/vendor/autoload.php';
    \Disembark\Run::main($argv, $argc);
}